
\chapter{Fundamentals}

An overview of the system and methods used is provided in this chapter, serving as a foundation for the more detailed examination of the approaches that follows. 

\section{The Extensible Neuroimaging Archive Toolkit}
The \ac{XNAT} ~\cite{marcus_extensible_2007} is an open-source imaging informatics platform developed by the Neuroinformatics Research Group at Washington University. It facilitates common management, productivity, and quality assurance tasks for imaging and associated data. Due to the fact that XNAT offers the opportunity to use the power of high-performance computing on your data~\cite{zaschke_extending_2024}, 
pipeline processing is one of the options that can be done on XNAT, as well as the deployment of Docker Containers.


\section{The REST API}
\ac{REST} is defined by its architectural contrainst, not by specific protocol or standars, such as API, allowing for various deployment approaches by API developers.
An \ac{API} is a set of terminology and standards for building and integrating application software. Those two are the main ingredients to achieve a automation of the analytical methods.  Luckily, XNAT provides its users with a list of REST APIs that make the exchange between the user and the website possible. 
 \footnote{\url{https://www.redhat.com/en/topics/api/what-is-a-rest-api}{ last accessed 07.09.2025}}

\section{The Docker Container}
A Container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another.\footnote{\url{https://www.docker.com/resources/what-container/} { last accessed on 10 August 2025}}
Docker is a platform that allows certain applications to run in software containers. It was launched in 2013.\footnote{\url{https://fr.wikipedia.org/wiki/Docker\_(logiciel)} { last accessed on 10 August 2025}} A Docker Container allows the user to deploy any application in any environment without worrying about incompatibility issues, regardless of the machineâ€™s configuration settings.\footnote{\url{https://sematext.com/glossary/docker/} {last accessed on 10 August 2025}} Although there are some associated terms that will always be needed when it comes to using or learning about Docker Containers.
One of the most important of them is the Dockerfile. The Dockerfile is a file that contains the build instructions for the image that the Docker Engine (an open-source containerization technology for building and containerizing your applications\footnote{\url{https://docs.docker.com/engine/} { last accessed on 10 August 2025}} will run. Conversely, there are numerous commands that must be written in the Dockerfile in order to create the image. After building the image, we can tag and push the image to Docker Hub. For this purpose, we just have to run some basic simple commands on a terminal.
\\
\section{Command Definition in JSON Format}
At the same time, if we want XNAT to execute a created Docker image and run a command, a \ac{JSON} command definition in JSON format is needed. 

The command definition in JSON format is a structured set of properties that defines the Docker image, which enables XNAT to execute the command correctly.\footnote{\url{https://wiki.xnat.org/container-service/json-command-definition}, { last accessed 23.08.2025}}

In other words, this command definition in JSON format (written in JSON) can be seen as a configuration for XNAT. When defining a command for XNAT in JSON format, the Docker image and a clear, human-readable name are specified, along with the exact command-line invocation, what input files are required and where they are mounted, how those inputs are selected from XNAT, and what outputs are produced and where they should be uploaded back into XNAT.\footnote{\url{https://wiki.xnat.org/container-service/json-command-definition}, { last accessed 23 August 2025}}
\section{Pipeline in XNAT}
Pipelines in XNAT are efficient lightweight applications that can be run on the project data to facilitate sophisticated processing tasks or leverage the computational power of extensive computing clusters. Some pipeline-enabled workflows run automatically, such as auto-QC of images, and some of them require manual steps, like defining a region of interest. After integrating the pipeline in project data, we can set up project-based workflows with project-specific and experiment-specific parameters, track a pipeline and send email notifications, and capture provenance information as the pipeline executes.\footnote{\url{https://wiki.xnat.org/documentation/running-pipelines-in-xnat} { last accessed 07.09.2025}} The pipelines are used for tasks like converting DICOM to NIFTI, performing image quality assessment (QA), correcting MRI bias fields, and running advanced analyses such as the FreeSurfer pipeline.\footnote{\url{https://github.com/jhuguetn/xnat-pipelines }{ last accessed 07.09.2025}}

\section{The Pipeline Descriptor}

Pipelines are identified by using a pipeline descriptor and resource descriptors. A resource descriptor describes an executable. An executable is identified by its name, its location, and the arguments that it takes.\footnote{\url{https://wiki.xnat.org/documentation/xnat-pipeline-development-schema }{ last accessed 07.09.2025}} In other words, the Pipeline Descriptor is a recipe of the pipeline that tells XNAT exactly what a pipeline is, what input is needed, and where the output should be located, ensuring a seamless integration in XNAT.








