\chapter{Comprehensive Analysis}
In this chapter starts the comprehensive analysis for both Docker Container method and the Pipeline method. 
Providing a full comparison and disadvantage and advantages for both method.
\section{Docker Method}
\subsection{The Docker Container Workflow in XNAT}

When running a Docker Container manually in XNAT, data is automatically provided, processed, and results are reloaded. The system first generates a JSON specification with script details, inputs, and outputs. XNAT then prepares the relevant data, copies it to a temporary host directory, and mounts it for container access. The Docker container processes the input, produces results, and writes them back to the host.
The diagram below illustrates the workflow data for a clearer understanding.  
The \autoref{fig:workflow} explains the workflow data in XNAT.

\begin{figure}[H]
    \centering
    \def\svgwidth{\linewidth} 
    \input{xnat.pdf_tex}
    \caption{Diagram: XNAT Workflow for Container Integration.}
    \label{fig:workflow}
\end{figure}


The Docker Container method is a suitable way to integrate AI into XNAT, working well with multiple data types and its recommended from the XNAT Documentation to launch jobs with the Docker Container method. However the method proved to have capabilities and limitations.

With the Docker Container method we could achieve a complete automatization of the workflow from creating the Dockerfile to launching the container. 
With the automatization we could select a specific file or more handle it to the container and the result file transfer was successful.
This automation also enables users to configure containers for a desired project data level (e.g., project, subject, scans), select files within that level, and process them with the container.
However, when only one context(project) is defined, and the container was charged with all project levels files, this one couldn't receive any file from the REST API call, even though the files were listed in the container information but still no successful transfer of files.  

Since it was confirmed from a Senior Software Developer in XNAT team developers that the containers do not have direct access to the database by default and the only way to do it is this by passing credentials to the container (or using some sort of secret store like Vault or Keycloak). This method is though not recommended because the developer warned that the action is unwise and even if the security problems are ignored there is no insignificant chance of causing a harm.
XNAT relies on a database to keep track of projects, subjects, sessions, files, etc. If this database is modified or interfered manually , XNAT might not understand the state of its own data anymore and things may appear missing or inconsistent in the UI or in the worst case breaks the the database altogether, meaning XNAT might stop working entirely.
It was also warned that even trying to connect directly the container to the XNAT database from inside the container it probably not work too. Because the PostgreSQL has security restriction that control which machines can connect to it, furthermore only specific IP addresses or networks that are allowed to connect with it. Which would completely break containers running under Docker Swarm or Kubernetes~\cite{database}. Which confirms why the container couldn't receive any file when he was provided with data coming from other contexts than the one defined in the JSON command. 





\subsection{Generalizability of the Docker Method}
To improve generalizability and accessibility especially for non-programming users the method could be extended with a graphical user interface (GUI), making it easier to apply across different institutions, datasets, and environments. 
\normalsize
\subsubsection{GUI Mockup for Docker Container Automation in XNAT}
\normalsize
To improve accessibility and usability for non-technical users, the Docker Container  automation script was visualized as a GUI mockup. As shown in the \autoref{fig:mockup}, this mockup demonstrates how the command-line workflow appears, following the same logical steps: (1) container configuration, (2) project selection, (3) file discovery, (4) container launch, and (5) result visualization.
\normalsize
\begin{figure}[htbp]
    \centering
    \def\svgwidth{\linewidth} 
    \input{mockup.pdf_tex}
    \caption{ Mockup Example for the Automation Script.}
    \label{fig:mockup}
\end{figure}
\normalsize
\subsection{The Docker Container Approach and the Somnolink Project}

The Somnolink project is a nationwide initiative to improve the treatment and research of obstructive sleep apnea through better data sharing. The obstructive sleep apnea is the most prevalent disorder in clinical sleep laboratories. Therefore, the main goals of the Somnolink project are (1) improvement of availability of sleep data at point of care, (2) improvement of the early diagnosis and (3) personalized therapy of OSA and (4) therapy adherence prediction.
The objectives of the project are aligned with the health data typically collected along the usual patient pathway. It consists of four stages: (1) assessing pre-test probability through medical history and questionnaires, (2) conducting physical examinations in primary care, (3) performing outpatient sleep diagnostics, and (4) carrying out comprehensive sleep laboratory studies. Based on this structure, which data are relevant at each step is identified and ML models are proposed that could assist clinicians in their decision-making ~\cite{krefting_somnolink_2025}. A central hub consisting of XNAT will manage the sleep data among the patient pathway and the AI models as a second opinion.
\begin{figure}[H]
    \centering
    \def\svgwidth{\linewidth} 
    \input{Somnolink.pdf_tex}
    \caption{Diagram: The Docker Container and the Somnolink project.}
    \label{fig:somnolink}
\end{figure}

In general, the implementation of Docker container technology is becoming increasingly prevalent within the Somnolink Project, due to it is notable that the models can be implemented with a Docker container within XNAT.
In this context, automating the Docker Container in XNAT offers a significant advantages. It allows the Somnolink predictions to be executed in a standardized manner. Such an automation not only reduces the manual intervention, but also ensures a consistent  workflow and facilitating the integration of data-driven decision support into clinical practice, which contribute to the project goals.\\
The \autoref{fig:somnolink} illustrates the structure of the OSA diagnostic pathway in relation to data collection, data driven support, and technical implementation.
The blue column shows the four steps of the German OSA patient pathway. The middle column summarizes the typical health data collected at each stage. And the last column underline the opportunity where machine learning or decision-support methods can be applied. 
The yellow banner highlights Docker container automation in XNAT  as the technical foundation that enable standardized and reproducible workflows across the steps.

\subsection{Sustainability Aspects of the Docker Container Including FAIR Criteria}
Sustainability within Somnolink project covers both the technical stability and scientific traceability. Consequently the use of the Docker Containers contribute by offering reproducible computational environments, reducing maintenance demands, and facilitating collaboration across multiple sites. However, conformity to FAIR principles strengthens the long-term reusability of the developed solutions: The Container images are well stored in the Docker Hub (Findable), they are also accessible via standardized interfaces (Accessible), employ interoperable data formats (Interoperable), and are adaptable for use in new contexts (Reusable). This harmonized approach is essential for ensuring sustainable support of the Somnolink project’s objectives. 
Another key strength for the developed automation script is its sustainability and long-term usability. The implementation is flexible and allows at the same time to the developers a reuse of the existing framework and modify only components that may need updating. Potential future changes may include updates to XNAT REST API endpoints, the introduction of new authentication methods, or alterations to the JSON-based schema for command and wrapper definitions. Additionally, existing Docker base images could become deprecated, or XNAT project structures might be extended with new contexts or data types. However, the core workflow logic would remain unaffected.

\section{Pipeline method}

\subsection{Generalizability of the Pipeline}
\normalsize
To generalize a pipeline and to make it transferable to any user, including those limited informatics expertise, presents several challenges.
Since the method requires manual transfer of the XML descriptor,  and the available endpoints are limited. 
However, it is possible to design a template for the XML descriptor and create a Python script that collects information from the user and substitutes it into the template. Additionally, a graphical user interface (GUI) could be developed to facilitate inserting the pipeline into XNAT. However, because the REST API offers only limited functionality, such a GUI cannot fully communicate the pipeline to XNAT.



%Template für XML bauen
%\url{https://groups.google.com/g/xnat_discussion/c/nFNfCx4K2SA/m/wj8N6VtVAQAJ}
%\url{https://groups.google.com/g/xnat_discussion/c/-1LlALF1vpQ/m/APPP90ofRzAJ}
%\url{https://groups.google.com/g/xnat_discussion/c/ewhjL7upJf4/m/0Soz5-sBEzwJ}



\subsection{The Pipeline Approach and the Somnolink Project, Sustainability Aspects Including FAIR Criteria}
The pipeline approach presents challenges adhering to FAIR principles.
Pipeline descriptors are stored in locally on the XNAT server and are not systematically indexed or searchable (limited Findability).
 Accessibility is also restricted, as only administrators have the necessary permissions to manually register and configure the XML files (limited accessibility).
 Interoperability is limited because the XML descriptors are closely tied to specific XNAT data types (limited interoperability). Additionally, the potential for reuse is also limited, since adapting a pipeline to new contexts necessitates manual transfer of XML files and server access configurations (limited reusability). Within the Somnolink project, the pipeline could play a great role as workflow  facilitating the structured execution of analysis steps in the Obstructive Sleep Apnea (OSA) diagnostic. By defining a sequence of processing tasks on a manual procedure. However, the practical use of pipelines is limited, as they require direct server access and technical configuration, which makes the pipeline more suitable for developers or system administrators than for clinicians, therefore reducing the the ability of a method to be use easily across different hospitals, research centers, or clinical teams, not just by a few developers with server access.


\section{Evaluating Pipeline and Docker Approaches in XNAT}

For the purpose of evaluating the two methods, we began by compiling a comparative table to provide a clearer understanding of their respective features.

\begin{table}[H]
  \centering
  \caption{Comprehensive comparison of XNAT Pipeline method and Docker Container method.}
  \label{tab:pipeline-vs-docker}

  \begin{tabular}{|>{\centering\arraybackslash}p{2cm}|
                      >{\centering\arraybackslash}p{4cm}|
                      >{\centering\arraybackslash}p{4cm}|
                      >{\centering\arraybackslash}p{4cm}|}
    \hline
    \textbf{Aspect} & \textbf{The Pipeline method} & \textbf{Docker Container method} & \textbf{Docker method with Automatization }\\ \hline
    
    
    Installation & Requires manual placement of XML descriptors, plugin JARs\footnote{\url{https://wiki.xnat.org/documentation/installing-the-pipeline-engine} last accessed 07.10.2025}, and executables on the server. & Container image uploaded once (via Docker registry) and configured in XNAT. & The automatization script must be launched and the Docker Engine must be installed and started up as well. \\ \hline
    

    
    Configuration & Admin must edit data types, enable actions, and rebuild Pipeline engine, require direct access to the server in order to manually copy the XML descriptor and associated scripts to a specific directory. & Minimal configuration through a JSON command, no engine rebuild needed. & No need for any configuration, the script carries the workflow to the end. \\ \hline
    
    Execution & The Run Pipeline option must be built via actions menu. & Triggered via actions menu or REST API, image runs in isolated environment. & The Docker Container is enabled automatically sitewide and project wide too. \\ \hline

    Deployability and flexibility & Pipelines are highly dependent on the specific XNAT environment and server configuration in which they are deployed. & Docker images can be reused in various XNAT installations and environment. & Automatically deploying within XNAT, after that the images can be reused in different environment. \\ \hline
    
    Maintenance & Requires server access and manual reconfiguration. & Updating requires building and pushing a new image, no direct server changes needed. & Old image can be deleted and then creating new images with updated external script.\\ \hline
    
    Usability & Requires XML schema knowledge and direct server administration. & Requires Docker knowledge, but easier to reuse prebuilt images, through running basic commands on terminal. & Extreme low knowledge requirement (except writing a requirement file and answering the script questions. \\ \hline
    
    Consistency & Depends on identical server setups and configurations. & High reproducibility is achieved, as all dependencies are within the container. & All dependencies are within the container, since the user has written the requirement file separately. \\ \hline
    
    Community & Limited documentation and less support from XNAT Community. & Huge support from XNAT community. & Big support as well. \\ \hline
    
    Security & Credentials needed in XML configuration. & Isolated container environments. & Isolated container environments. \\ \hline
  \end{tabular}
\end{table}

 The table \ref{tab:pipeline-vs-docker} has been added to present a direct comparison between the two methods.




 
\subsection{Advantages and Disadvantages of the Methods}

After comparing both approaches in terms of installation, configuration, automation, and maintenance (see ~\autoref{tab:pipeline-vs-docker}), a summary of their main advantages and disadvantages is provided in ~\autoref{tab:docker_pipeline}.

\begin{table}[htbp]
\centering
\caption{Advantages and disadvantages of the Pipeline method and Docker Container method in XNAT.}
\label{tab:adv-disadv}
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{|p{3cm}|p{3cm}|p{5cm}|p{4cm}|}
\hline
\textbf{Aspect} & \textbf{Pipeline Method} & \textbf{Docker Container Method} & \textbf{Automatization of the Docker method} \\
\hline
\textbf{Advantages} &
\parbox[t]{3cm}{
- Fully compatible with older XNAT versions~\cite{Pipelinecompatible}.\\
- The execution of external applications and shell scripts is possible ~\cite{jansen_extending_2015}.
}
&
\parbox[t]{5cm}{
- Easy installation (Docker Engine). \\
- Minimal configuration via JSON-based command.\\
- Highly reusable across XNAT servers. \\
- Easier updates by building and pushing a new image. \\
- Large community support.\\
- Secure via isolated container environment. \\
- Docker images stored on Docker Hub can be used in different clinics and research institutions.\\
}
&
\parbox[t]{4cm}{
- No configuration needed. \\
- Extremely low knowledge requirement (only need to write a requirements file). \\
- All manual steps automated. \\
- The script asks simple questions. \\
- Time saving compared to the manual Docker method. \\
- Images reusable across environments and institutes. \\
- Images securely stored in Docker Hub and within XNAT.\\
} \\
\hline
\textbf{Disadvantages} &
\parbox[t]{3cm}{
- Requires manual placement of XML descriptors.\\
- Needs server access for installation and updates.\\
- Requires XML schema knowledge.\\
- Limited automation support and no automation achievable.\\
- The pipeline has to be  removed or disabled after the running, to prevent users from running this pipeline in the future~\cite{addingpipeline}.\\
- The pipeline is not a preferred way to launch jobs in XNAT.\\

}
&
\parbox[t]{6cm}{
- Requires Docker knowledge. \\
- Depends on Docker availability \\if Docker is blocked or fails, \\images are not recognized\\ within XNAT. \\
- Requires regular expression\\ knowledge for file filtering. \\
- No access to the database. \\
- Mounting extracted files \\ consumes significant \\storage space.\\
}
&
\parbox[t]{4cm}{
- Works better with launching multiple containers. \\
- Problems launching a single container. \\
- For specific file processing, the JSON command in the script must be adjusted with an extra matcher.
} \\
\hline
\end{tabular}
\label{tab:docker_pipeline}
\end{table}


\section{Measures for the Future for both Methods}

The Docker Container method is determined to be better than the Pipeline method, as shown in the table above the Docker Container is a simplified and secure method.  
The Docker Container method offers significant advantages over the Pipeline method in XNAT.
Almost all the steps of the Docker Container are simplified and requiring minimal steps compared to the Pipeline method. Furthermore it provides a better automation through the REST API support.  Furthermore, Docker's usability is improved with prebuilt image reusability, high reproducibility, strong community support, and enhanced security through isolated container environments, ultimately making it a more efficient and manageable solution.

Looking ahead, both methods have potential for future development.\\
For the Pipeline method, future development should focus on two key areas: Firstly, establishing a secure pipeline Hub to centralize storage and enhance environmental security. Secondly, integrating XML deployment directly within XNAT would streamline the build process for the "Run Pipeline" option, eliminating the need for server access and simplifying overall usability.\\
Future development of the Docker Container method should focus on: Firstly, enabling direct access to the XNAT database to facilitate comprehensive file processing across the entire project. Secondly, enhancing the JSON command to allow re-uploading processed files to various output locations within XNAT, regardless of the initial file selection. This would ensure that processed files are returned to their original locations, streamlining data management and improving workflow efficiency.
