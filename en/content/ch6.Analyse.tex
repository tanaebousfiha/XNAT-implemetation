\chapter{Comprehensive Analysis}
This chapter conducts the comprehensive analysis for both methods Docker Container and Pipeline. 
A full comparison with and disadvantages and advantages for both methods are presented.
\section{Docker Method}
\subsection{The Docker Container workflow in XNAT}

XNAT provides data flow for manually run Docker containers. It generates a JSON specification, prepares and mounts data, and reloads the container's results.
The diagram below illustrates the workflow data for a clearer understanding.  
The \autoref{fig:workflow} explains the workflow data in XNAT.

\begin{figure}[H]
    \centering
    \def\svgwidth{\linewidth} 
    \input{xnat.pdf_tex}
    \caption{Diagram: XNAT Workflow for Container Integration.}
    \label{fig:workflow}
\end{figure}

\subsection{Generalizability of the Docker method}
The Docker Container method is a suitable way to integrate AI into XNAT, working well with multiple data types and its recommended from the XNAT Documentation to launch jobs with the Docker Container method. Complete workflow automation was achieved with the Docker Container method, enabling users to select and transfer specific files to the container at various project data levels. However, the REST API call failed to transfer all project-level files to a single container, despite the files being listed in the container information.  

A senior XNAT developer confirmed that containers lack direct database access by default, requiring credential passing (or a secret store like Vault or Keycloak)~\cite{database}. However, this approach is strongly discouraged due to potential security risks and the possibility of causing harm to the database. Direct container-database connection is unlikely due to PostgreSQL's IP restrictions, which would break containers in Docker Swarm/Kubernetes and explains why the container couldn't receive files from different contexts.
While the senior developer confirmed that retrieving files via REST API during container execution is a valid approach, no files were successfully transferred to the container in practice.

To improve generalizability and accessibility especially for non-programming users the method could be extended with a graphical user interface (GUI), making it easier to apply across different institutions, datasets, and environments. 
\normalsize
\subsubsection{GUI Mockup for Docker Container automation in XNAT}
\normalsize
To improve accessibility and usability for non-technical users, the Docker Container  automation script was visualized as a GUI mockup. As shown in the \autoref{fig:mockup}, this mockup demonstrates how the command-line workflow appears, following the same logical steps: (1) Login credentials, (2) Python script path, (3) Description of the command, (4) Project ID, and (5) Launching the container.
\normalsize
\begin{figure}[H]
    \centering
    \def\svgwidth{\linewidth} 
    \input{mockup.pdf_tex}
    \caption{ Mockup Example for the Automation Script.}
    \label{fig:mockup}
\end{figure}
\normalsize
\subsection{The Docker Container approach and the somnolink project}

The Somnolink project aims to improve obstructive sleep apnea (OSA) treatment and research by enhancing data sharing nationwide. Its primary goals include improving data availability, early diagnosis, personalized therapy, and therapy adherence prediction for OSA, the most common disorder in sleep labs.

The objectives of the project are aligned with the health data typically collected along the usual patient pathway. It consists of four stages: (1) assessing pre-test probability through medical history and questionnaires, (2) conducting physical examinations in primary care, (3) performing outpatient sleep diagnostics, and (4) carrying out comprehensive sleep laboratory studies. Based on this structure, which data are relevant at each step is identified and ML models are proposed that could assist clinicians in their decision-making ~\cite{krefting_somnolink_2025}. A central hub consisting of XNAT will manage the sleep data among the patient pathway and the AI models as a second opinion.
\begin{figure}[H]
    \centering
    \def\svgwidth{\linewidth} 
    \input{Somnolink.pdf_tex}
    \caption{Diagram: The Docker Container and the somnolink project.}
    \label{fig:somnolink}
\end{figure}

The usage of Docker containers within the Somnolink Project allows for model implementation within XNAT. Automating these containers standardizes the execution of Somnolink predictions, reducing manual effort, ensuring workflow consistency, and facilitating data-driven clinical decision support, thereby supporting the project's objectives.\\
The \autoref{fig:somnolink} illustrates the structure of the OSA diagnostic pathway in relation to data collection, data driven support, and technical implementation.
\subsection{Sustainability Aspects of the Docker Container Including FAIR Criteria}
According to Wilkinson et al. ~\cite{FAIR}, "The FAIR guiding principles describe distinct considerations for contemporary data publishing environments with respect to supporting both manual and automated deposition, exploration, sharing, and reuse."


Sustainability within Somnolink project covers both the technical stability and scientific traceability. Consequently the use of the Docker Containers contribute by offering reproducible computational environments, reducing maintenance demands, and facilitating collaboration in XNAT. However, conformity to FAIR principles strengthens the long-term reusability of the developed solutions: The Container images are well stored in the Docker Hub (Findable), they are also accessible via standardized interfaces (Accessible), employ interoperable data formats (Interoperable), and are adaptable for use in new contexts (Reusable). 
Another key strength for the developed automation script is its sustainability and long-term usability. The implementation is flexible and allows at the same time to the developers a reuse of the existing framework and modify only components that may need updating. Potential future changes may include updates to XNAT REST API endpoints, the introduction of new authentication methods, or alterations to the JSON-based schema for command and wrapper definitions. Additionally, existing Docker base images could become deprecated, or XNAT project structures might be extended with new contexts or data types. However, the core workflow logic would remain unaffected.

\section{Pipeline method}
\subsection{Pipeline workflow in XNAT}
When a pipeline is launched, first XNAT reads the pipeline Descriptor XML, identifies the recourse descriptor, substitutes the variables defined in the Parameters File, and then executes the specified commands. The outputs are automatically captured and stored as XNAT resources.

\subsection{Generalizability of the pipeline}
\normalsize
To generalize a pipeline and to make it transferable to any user and to any user-case, including those with limited informatics expertise, presents several challenges.
Since the method requires manual transfer of the XML descriptor,  and the available endpoints are limited. 
However, it is possible to design a template for the XML descriptor and create a Python script that collects information from the user and substitutes it into the template. Additionally, a graphical user interface (GUI) could be developed to facilitate inserting the pipeline into XNAT. However, because the REST API offers only limited functionality, such a GUI cannot fully communicate the pipeline to XNAT.



%Template fÃ¼r XML bauen
%\url{https://groups.google.com/g/xnat_discussion/c/nFNfCx4K2SA/m/wj8N6VtVAQAJ}
%\url{https://groups.google.com/g/xnat_discussion/c/-1LlALF1vpQ/m/APPP90ofRzAJ}
%\url{https://groups.google.com/g/xnat_discussion/c/ewhjL7upJf4/m/0Soz5-sBEzwJ}



\subsection{The pipeline approach and the somnolink project, sustainability aspects including FAIR criteria}
The pipeline approach presents challenges adhering to FAIR principles.
Pipeline descriptors are stored in locally on the XNAT server and are not systematically indexed or searchable.
 Accessibility is also restricted, as only administrators have the necessary permissions to manually register and configure the XML files (limited accessibility).
 Interoperability is limited because the XML descriptors are closely tied to specific XNAT data types. Additionally, the potential for reuse is also limited, since adapting a pipeline to new contexts necessitates manual transfer of XML files and server access configurations. Within the Somnolink project, the pipeline could play a great role as workflow  facilitating the structured execution of analysis steps in the Obstructive Sleep Apnea (OSA) diagnostic. By defining a sequence of processing tasks on a manual procedure. However, the practical use of pipelines is limited, as they require direct server access and technical configuration, which makes the pipeline more suitable for developers or system administrators than for clinicians, therefore reducing the the ability of a method to be use easily across different hospitals, research centers, or clinical teams, not just by a few developers with server access.


\section{Evaluating pipeline and Docker approaches in XNAT}

For the purpose of evaluating the two methods, we began by compiling a comparative table to provide a clearer understanding of their respective features.

\begin{table}[H]
  \centering
  \caption{Comprehensive comparison of XNAT Pipeline method and Docker Container method.}
  \label{tab:pipeline-vs-docker}

  \begin{tabular}{|>{\centering\arraybackslash}p{2cm}|
                      >{\centering\arraybackslash}p{4cm}|
                      >{\centering\arraybackslash}p{4cm}|
                      >{\centering\arraybackslash}p{4cm}|}
    \hline
    \textbf{Aspect} & \textbf{The Pipeline method} & \textbf{Docker Container method} & \textbf{Docker method with Automatization }\\ \hline
    
    
    Installation & Requires manual placement of XML descriptors, plugin JARs\footnote{\url{https://wiki.xnat.org/documentation/installing-the-pipeline-engine} last accessed 07.10.2025}, and executables on the server. & Container image uploaded once (via Docker registry) and configured in XNAT. & The automatization script must be launched and the Docker Engine must be installed and started up as well. \\ \hline
    

    
    Configuration & Admin must edit data types, enable actions, and rebuild Pipeline engine, require direct access to the server in order to manually copy the XML descriptor and associated scripts to a specific directory. & Minimal configuration through a JSON command, no engine rebuild needed. & No need for any configuration, the script carries the workflow to the end. \\ \hline
    
    Execution & The Run Pipeline option must be built via actions menu. & Triggered via actions menu or REST API, image runs in isolated environment. & The Docker Container is enabled automatically sitewide and project wide too. \\ \hline

    Deployability and flexibility & Pipelines are highly dependent on the specific XNAT environment and server configuration in which they are deployed. & Docker images can be reused in various XNAT installations and environment. & Automatically deploying within XNAT, after that the images can be reused in different environment. \\ \hline
    
    Maintenance & Requires server access and manual reconfiguration. & Updating requires building and pushing a new image, no direct server changes needed. & Old image can be deleted and then creating new images with updated external script.\\ \hline
    
    Usability & Requires XML schema knowledge and direct server administration. & Requires Docker knowledge, but easier to reuse prebuilt images, through running basic commands on terminal. & Extreme low knowledge requirement (except writing a requirement file and answering the script questions. \\ \hline
    
    Consistency & Depends on identical server setups and configurations. & High reproducibility is achieved, as all dependencies are within the container. & All dependencies are within the container, since the user has written the requirement file separately. \\ \hline
    
    Community & Limited documentation and less support from XNAT Community. & Huge support from XNAT community. & Big support as well. \\ \hline
    
    Security & Credentials needed in XML configuration. & Isolated container environments. & Isolated container environments. \\ \hline
  \end{tabular}
\end{table}

 The table \ref{tab:pipeline-vs-docker} has been added to present a direct comparison between the two methods.




 
\subsection{Advantages and disadvantages of the methods}

After comparing both approaches in terms of installation, configuration, automation, and maintenance (see ~\autoref{tab:pipeline-vs-docker}), a summary of their main advantages and disadvantages is provided in ~\autoref{tab:docker_pipeline}.

\begin{table}[htbp]
\centering
\caption{Advantages and disadvantages of the Pipeline method and Docker Container method in XNAT.}
\label{tab:adv-disadv}
\renewcommand{\arraystretch}{4}
\begin{tabular}{|p{1cm}|p{3cm}|p{5cm}|p{4cm}|}
\hline
\textbf{Aspect} & \textbf{Pipeline Method} & \textbf{Docker Container Method} & \textbf{Automatization(Docker method)} \\
\hline
\textbf{Advan-tages} &
\parbox[t]{3cm}{
$\bullet$ Fully compatible with older XNAT versions~\cite{Pipelinecompatible}.\\
$\bullet$ Execution of external applications and shell scripts is possible ~\cite{jansen_extending_2015}.
}
&
\parbox[t]{5cm}{
$\bullet$ Easy installation (Docker Engine). \\
$\bullet$ Minimal configuration via JSON-based command.\\
$\bullet$ Highly reusable across XNAT servers. \\
$\bullet$ Easier updates by building and pushing a new image. \\
$\bullet$ Large community support.\\
$\bullet$ Secure via isolated container environment. \\
$\bullet$ Docker images stored on Docker Hub can be used in different clinics and research institutions.\\
}
&
\parbox[t]{3cm}{
$\bullet$ No configuration needed. \\
$\bullet$ Extremely low knowledge requirement . \\
$\bullet$ All manual steps automated. \\
$\bullet$ The script asks simple questions. \\
$\bullet$ Time saving compared to the manual Docker method. \\
$\bullet$ Images reusable across environments and institutes. \\
$\bullet$ Images securely stored in Docker Hub and within XNAT.\\
} \\
\hline
\textbf{Disadv-antages} &
\parbox[t]{3cm}{
$\bullet$ Requires manual placement of XML descriptors.\\
$\bullet$ Needs server access for installation and updates.\\
$\bullet$ Requires XML schema knowledge.\\
$\bullet$ Limited automation support and no automation achievable.\\
$\bullet$ The pipeline has to be  removed or disabled after the running~\cite{addingpipeline}.\\
$\bullet$ The pipeline is not a preferred way to launch jobs in XNAT.\\

}
&
\parbox[t]{6cm}{
$\bullet$ Requires Docker knowledge. \\
$\bullet$ Depends on Docker availability \\if Docker is blocked or fails, \\images are not recognized\\ within XNAT. \\
$\bullet$ Requires regular expression\\ knowledge for file filtering. \\
$\bullet$ No access to the database. \\

}
&
\parbox[t]{4cm}{
$\bullet$ Works better with launching multiple containers. \\
$\bullet$ Problems launching a single container. \\
$\bullet$ For specific file processing, the JSON command in the script must be adjusted, extended or modified.\\
$\bullet$ Selecting a XNAT level and launching with selected file is the successful model achieved. 
} \\
\hline
\end{tabular}
\label{tab:docker_pipeline}
\end{table}


\section{Measures for the future for both methods}

For the Pipeline method, future development should focus on three key areas: Firstly, establishing a secure pipeline Hub to centralize storage and enhance environmental security. Secondly, integrating XML deployment directly within XNAT would streamline the build process for the "Run Pipeline" option, eliminating the need for server access and simplifying overall usability. Thirdly supporting more REST API endpoints.\\
Future development of the Docker Container method should focus on: Firstly, enabling direct access to the XNAT database to facilitate comprehensive file processing across the entire project. Secondly, enhancing the JSON command to allow re-uploading processed files to various output locations within XNAT, regardless of the initial file selection. This would ensure that processed files are returned to their original locations, streamlining data management and improving workflow efficiency. And lastly implementing the GUI mockup for the automation.


