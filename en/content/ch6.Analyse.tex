\chapter{Comprehensive Analysis}
This chapter conducts the comprehensive analysis for both methods Docker Container and Pipeline. 
A full comparison with and disadvantages and advantages for both methods are presented.
\section{Docker Method}
\subsection{The Docker Container workflow in XNAT}

XNAT provides data flow for manually run Docker containers. It generates a JSON specification, prepares and mounts data, and reloads the container's results.
The diagram below illustrates the workflow data for a clearer understanding.  
The \autoref{fig:workflow} explains the workflow data in XNAT.

\begin{figure}[H]
    \centering
    \def\svgwidth{\linewidth} 
    \input{xnat.pdf_tex}
    \caption{Diagram: XNAT Workflow for Container Integration.}
    \label{fig:workflow}
\end{figure}

\subsection{Generalizability of the Docker method}
The Docker Container method is a suitable way to integrate AI into XNAT, working well with multiple data types and its recommended from the XNAT Documentation to launch jobs with the Docker Container method. Complete workflow automation was achieved with the Docker Container method, enabling users to select and transfer specific files to the container at various project data levels. However, the REST API call failed to transfer all project-level files to a single container, despite the files being listed in the container information.  

A senior XNAT developer confirmed that containers lack direct database access by default, requiring credential passing (or a secret store like Vault or Keycloak)~\cite{database}. However, this approach is strongly discouraged due to potential security risks and the possibility of causing harm to the database. Direct container-database connection is unlikely due to PostgreSQL's IP restrictions, which would break containers in Docker Swarm/Kubernetes and explains why the container couldn't receive files.
While the senior developer confirmed that retrieving files via REST API during container execution is a valid approach, no files were successfully transferred or mounted to the container in practice. 
XNAT was able to mount files from the same context but not able to mount the files from other contexts, what explains why when i proceeded files from the same context as the recourse the container could process them. 



To improve generalizability and accessibility especially for non-programming users the method could be extended with a graphical user interface (GUI), making it easier to apply across different institutions, datasets, and environments. 
\normalsize
\subsubsection{GUI Mockup for Docker Container automation in XNAT}
\normalsize
To improve accessibility and usability for non-technical users, the Docker Container  automation script was visualized as a GUI mockup. As shown in the \autoref{fig:mockup}, this mockup demonstrates how the command-line workflow appears, following the same logical steps: (1) Login credentials, (2) Python script path, (3) Description of the command, (4) Project ID, and (5) Launching the container.
\normalsize
\begin{figure}[H]
    \centering
    \def\svgwidth{\linewidth} 
    \input{mockup.pdf_tex}
    \caption{ Mockup Example for the Automation Script.}
    \label{fig:mockup}
\end{figure}
\normalsize
\subsection{The Docker Container approach and the Somnolink project}

The Somnolink project aims to improve obstructive sleep apnea (OSA) diagnose and  treatment and research by enhancing data sharing nationwide~\cite{krefting_somnolink_2025}. The primary goal of the project is to improve the diagnosis, treatment and adherence to treatment of patients with obstructive sleep apnea by using medical informatics and medical data science methods~\cite{aimsomnilink}.
In order to achieve this goal method of informatics and ML-based decisions support system are being used. 
The data source is chosen based on clinical practice, and the OSA patient pathway follows the four-step diagnostic process : (1) assessment of the pretest probability via anamnesis and questionnaires, (2) physical examination, (3) sleep diagnostics by an outpatient sleep specialist, (4) comprehensive diagnostics in a sleep lab ~\cite{krefting_somnolink_2025}.
The \autoref{fig:somnolink} illustrates the structure of the OSA diagnostic pathway in relation to data collection, and data science and ML support.
\begin{figure}[H]
    \centering
    \def\svgwidth{\linewidth} 
    \input{Somnolink.pdf_tex}
    \caption{Diagram: The Docker Container and the Somnolink project.}
    \label{fig:somnolink}
\end{figure}

The fact that the proposed solution for the Somnolink approaches is the ML-based screening of inpatient for OSA, and ML-based therapy response prediction, ML-based prediction of therapy discontinuation risk, the usage of Docker Containers within the Somnolink Project could facilitate the achievement of the project goals, by allowing model implementation within XNAT. Additionally  automating these containers workflows standardizes the execution of Somnolink predictions, reducing manual effort, ensuring workflow consistency, thereby supporting the project's objectives.\\









\subsection{Sustainability Aspects of the Docker Container Including FAIR Criteria}

According to Wilkinson et al. ~\cite{FAIR}, "The FAIR guiding principles describe distinct considerations for contemporary data publishing environments with respect to supporting both manual and automated deposition, exploration, sharing, and reuse."
The use of the Docker Containers contribute by offering reproducible computational environments, reducing maintenance demands, and facilitating collaboration in XNAT. However, analyzing this method concerning the FAIR criteria reveals the following:\\
$\bullet$ Findable(F1–F4):\\
The Docker images are assigned a globally unique and persistent identifier. Their metadata describes the container’s purpose, version, build date, author, and dependencies. Additionally they are registered or indexed in Docker Hub and can be stored in XNAT as well.\\
$\bullet$ Accessible (A1–A2):\\
The Docker images are also accessible via standardized interfaces and they are retrievable using open and standardized protocols(HTTPS, REST API). At the same time the images could be secured with private access. Even with the output file deleted from XNAT, the preserved metadata (filename, ID, container version, etc.) allows future researchers to verify the result's existence, understand its origin, and regenerate the data by re-running the workflow.\\
$\bullet$ Interoperable (I1–I3): \\
Standardized data formats and XNAT-compatible schemas in container outputs ensure seamless integration with other tools and enhance dataset compatibility.\\
$\bullet$ Reusable (R1–R1.3):\\
While Docker containers include detailed metadata promoting reuse, the image owner retains the right to make the image private, limiting accessibility~\cite{FAIR}.











Another key strength for the developed automation script is its sustainability and long-term usability. The implementation is flexible and allows at the same time to the developers a reuse of the existing framework and modify only components that may need updating. Potential future changes may include updates to XNAT REST API endpoints, the introduction of new authentication methods, or alterations to the JSON-based schema for command and wrapper definitions. Additionally, existing Docker base images could become deprecated, or XNAT project structures might be extended with new contexts or data types. However, the core workflow logic would remain unaffected.

\section{Pipeline method}
\subsection{Pipeline workflow in XNAT}
When a pipeline is launched, first XNAT reads the pipeline Descriptor XML, identifies the recourse descriptor, substitutes the variables defined in the Parameters File, and then executes the specified commands. The outputs are automatically captured and stored as XNAT resources.

\subsection{Generalizability of the pipeline}
\normalsize
To generalize a pipeline and to make it transferable to any user and to any user-case, including those with limited informatics expertise, presents several challenges.
Since the method requires manual transfer of the XML descriptor,  and the available endpoints are limited. 
However, it is possible to design a template for the XML descriptor and create a Python script that collects information from the user and substitutes it into the template. Additionally, a graphical user interface (GUI) could be developed to facilitate inserting the pipeline into XNAT. However, because the REST API offers only limited functionality, such a GUI cannot fully communicate the pipeline to XNAT.



%Template für XML bauen
%\url{https://groups.google.com/g/xnat_discussion/c/nFNfCx4K2SA/m/wj8N6VtVAQAJ}
%\url{https://groups.google.com/g/xnat_discussion/c/-1LlALF1vpQ/m/APPP90ofRzAJ}
%\url{https://groups.google.com/g/xnat_discussion/c/ewhjL7upJf4/m/0Soz5-sBEzwJ}



\subsection{The pipeline approach and the Somnolink project, sustainability aspects including FAIR criteria}
The pipeline approach presents challenges adhering to FAIR principles.
Pipeline descriptors are stored in locally on the XNAT server and are not searchable.
Accessibility is also restricted, as only administrators have the necessary permissions to manually register and configure the XML files.
Additionally, the potential for reuse is also limited, since adapting a pipeline to new contexts necessitates manual transfer of XML files and server access configurations. 
After creating and successfully testing the pipeline, the pipeline owners can secure their pipeline descriptors using file system permissions, so that they can be accessed or transmitted by the owner. However the other users must configure all other steps to integrate the pipeline on their own XNAT.
The practical use of pipelines is limited, as they require direct server access and technical configuration, which makes the pipeline not suitable for developers, system administrators or clinicians.


\section{Evaluating pipeline and Docker approaches in XNAT}

For the purpose of evaluating the two methods, i began by compiling a comparative table to provide a clearer understanding of their respective features.

\subsection{Advantages and disadvantages of the methods}

After comparing both approaches in terms of installation, configuration, automation, and maintenance (see ~\autoref{tab:pipeline-vs-docker}), a summary of their main advantages and disadvantages is provided in ~\autoref{tab:docker_pipeline}.

\begin{table}[htbp]
\centering
\caption{Advantages and disadvantages of the Pipeline method and Docker Container method in XNAT.}
\label{tab:adv-disadv}
\renewcommand{\arraystretch}{4}
\begin{tabular}{|p{1cm}|p{3cm}|p{5cm}|p{4cm}|}
\hline
\textbf{Aspect} & \textbf{Pipeline Method} & \textbf{Docker Container Method} & \textbf{Automatization (Docker method)} \\
\hline
\textbf{Advan-tages} &
\parbox[t]{3cm}{
$\bullet$ Fully compatible with older XNAT versions~\cite{Pipelinecompatible}.\\
$\bullet$ Execution of external applications and shell scripts is possible ~\cite{jansen_extending_2015}.
}
&
\parbox[t]{5cm}{
$\bullet$ Easy installation (Docker Engine). \\
$\bullet$ Minimal configuration via JSON-based command.\\
$\bullet$ Highly reusable across XNAT servers. \\
$\bullet$ Easier updates by building and pushing a new image. \\
$\bullet$ Large community support.\\
$\bullet$ Secure via isolated container environment. \\
$\bullet$ Docker images stored on Docker Hub can be used in different clinics and research institutions.\\
}
&
\parbox[t]{3cm}{
$\bullet$ No configuration needed. \\
$\bullet$ Extremely low knowledge requirement . \\
$\bullet$ All manual steps automated. \\
$\bullet$ The script asks simple questions. \\
$\bullet$ Time saving compared to the manual Docker method. \\
$\bullet$ Images reusable across environments, because they are stored in the Docker Hub. \\
$\bullet$ Images securely stored in Docker Hub and within XNAT.\\
} \\
\hline
\textbf{Disadv-antages} &
\parbox[t]{3cm}{
$\bullet$ Requires manual placement of XML descriptors.\\
$\bullet$ Needs server access for installation and updates.\\
$\bullet$ Requires XML schema knowledge.\\
$\bullet$ Limited automation support and no automation achievable.\\
$\bullet$ The pipeline has to be  removed or disabled after the running~\cite{addingpipeline}.\\
$\bullet$ The pipeline is not a preferred way to launch jobs in XNAT.\\

}
&
\parbox[t]{6cm}{
$\bullet$ Requires Docker knowledge. \\
$\bullet$ Depends on Docker availability \\if Docker is blocked or fails, \\images are not recognized\\ within XNAT. \\
$\bullet$ Requires regular expression\\ knowledge for file filtering. \\
$\bullet$ No access to the database. \\

}
&
\parbox[t]{4cm}{
$\bullet$ Problems launching a single container. \\
$\bullet$ For specific file processing, the JSON command in the script must be adjusted, extended or modified.\\
$\bullet$ Selecting a XNAT level and launching with selected file is the successful model achieved. 
} \\
\hline
\end{tabular}
\label{tab:docker_pipeline}
\end{table}


\section{Measures for the future for both methods}

For the Pipeline method, future development should focus on three key areas: Firstly, establishing a secure pipeline Hub to centralize storage and enhance environmental security. Secondly, integrating XML deployment directly within XNAT would streamline the build process for the "Run Pipeline" option, eliminating the need for server access and simplifying overall usability. Thirdly supporting more REST API endpoints.\\
Future development of the Docker Container method should focus on: Firstly, enabling direct access to the XNAT database to facilitate comprehensive file processing across the entire project. Secondly, enhancing the JSON command to allow re-uploading processed files to various output locations within XNAT, regardless of the initial file selection. This would ensure that processed files are returned to their original locations. And lastly implementing the GUI mockup for the automation.
Additionally it is preferable to create a new REST API endpoint for launching containers, within this one a placement for the \texttt{input files} are given, since i faced a problem with communicating the files to the container with REST API, in order to avoid communicating the files through a payload, and obviously this would not be successful if the mounting is restricted for only the defined context. 

\begin{table}[H]
  \centering
  \caption{Comprehensive comparison of XNAT Pipeline method and Docker Container method.}
  \label{tab:pipeline-vs-docker}

  \begin{tabular}{|>{\centering\arraybackslash}p{2cm}|
                      >{\centering\arraybackslash}p{4cm}|
                      >{\centering\arraybackslash}p{4cm}|
                      >{\centering\arraybackslash}p{4cm}|}
    \hline
    \textbf{Aspect} & \textbf{The Pipeline method} & \textbf{Docker Container method} & \textbf{Docker method with Automatization }\\ \hline
    
    
    Installation & Requires manual placement of XML descriptors, plugin JARs~\cite{installpipeline}, and executables on the server. & Container image uploaded once (via Docker registry) and configured in XNAT. & The automatization script must be launched and the Docker Engine must be installed and started up as well. \\ \hline
    

    
    Configuration & Admin must edit data types, enable actions, and rebuild Pipeline engine, require direct access to the server in order to manually copy the XML descriptor and associated scripts to a specific directory. & Minimal configuration through a JSON command, no engine rebuild needed. & No need for any configuration, the script carries the workflow to the end. \\ \hline
    
    Execution & The Run Pipeline option must be built via actions menu. & Triggered via actions menu or REST API, image runs in isolated environment. & The Docker Container is enabled automatically sitewide and project wide too. \\ \hline

    Deployability and flexibility & Pipelines are highly dependent on the specific XNAT environment and server configuration in which they are deployed. & Docker images can be reused in various XNAT installations and environment. & Automatically deploying within XNAT, after that the images can be reused in different environment. \\ \hline
    
    Maintenance & Requires server access and manual reconfiguration. & Updating requires building and pushing a new image, no direct server changes needed. & Old image can be deleted and then creating new images with updated external script.\\ \hline
    
    Usability & Requires XML schema knowledge and direct server administration. & Requires Docker knowledge, but easier to reuse prebuilt images, through running basic commands on terminal. & Extreme low knowledge requirement (except writing a requirement file and answering the script questions. \\ \hline
    
    
    Security & Credentials needed in XML configuration. & Isolated container environments. & Isolated container environments. \\ \hline
  \end{tabular}
\end{table}

 The table \ref{tab:pipeline-vs-docker} presents a direct comparison between the two methods.
