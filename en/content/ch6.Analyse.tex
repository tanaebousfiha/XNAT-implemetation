\chapter{Comprehensive Analysis}
\section{Docker Method}
%result and discussion 

When running a Docker Container manually in XNAT, data is automatically provided, processed, and results are reloaded. The system first generates a JSON specification with script details, inputs, and outputs. XNAT then prepares the relevant data, copies it to a temporary host directory, and mounts it for container access. The Docker container processes the input, produces results, and writes them back to the host.
While containers can handle many files (with limits adjustable via ulimit), this approach exposes a key issue: containers lack direct access to the XNAT database. Instead, data copying and mounting may cause host memory or disk space problems, especially with large datasets. In testing, failures occurred even with small datasets, suggesting the issue is not only due to size or resource limits.
The diagram below illustrates the workflow data for a clearer understanding.  
The \autoref{fig:workflow} explains the workflow data in XNAT.

\begin{figure}[H]
    \centering
    \def\svgwidth{\linewidth} 
    \input{xnat.pdf_tex}
    \caption{Diagram: XNAT Workflow for Container Integration.}
    \label{fig:workflow}
\end{figure}

%-------------------------------------------------------------------------


The Docker Container method is a suitable way to integrate AI into XNAT, working well with multiple data types like CSV or DICOM. However the method proved to have capabilities and limitations.
Automation is a key benefit, enabling the launch of single or multiple workflows via scripts. Docker container automation allows users to select specific files and launch the container. This automation also enables users to configure containers for a desired project data level (e.g., project, subject, scans), select files within that level, and process them with the container.
After testing both manual and automated Docker Container workflows, we identified several limitations requiring further attention. First, the Docker Container lacks access to the database, preventing complete processing of all files within an XNAT project. Second, mounting extracted files consumes a significant amount of storage space, leading to space limitations.
Furthermore to process all files across a project, extra steps are required: gathering data from all structures and relocating outputs to their original directories.
Another point is the file filtering that can be set through the JSON based Command, in case the user want to process only certain formats (e.g., CSV, TXT, DICOM).

\subsection{Generalizability of the Docker Method}
To improve generalizability and accessibility especially for non-programming users the method could be extended with a graphical user interface (GUI), making it easier to apply across different institutions, datasets, and environments. 
\normalsize
\subsubsection{GUI Mockup for Docker Container Automation in XNAT}
\normalsize
To improve accessibility and usability for non-technical users, the Docker Container  automation script was visualized as a GUI mockup. As shown in the \autoref{fig:mockup}, this mockup demonstrates how the command-line workflow appears, following the same logical steps: (1) container configuration, (2) project selection, (3) file discovery, (4) container launch, and (5) result visualization.
\normalsize
\begin{figure}[htbp]
    \centering
    \def\svgwidth{\linewidth} 
    \input{mockup.pdf_tex}
    \caption{ Mockup Example for the Automation Script.}
    \label{fig:mockup}
\end{figure}
\normalsize
\subsection{The Docker Container Approach and the Somnolink Project, Sustainability Aspects Including FAIR Criteria}

The Somnolink project is a nationwide initiative to improve the treatment and research of obstructive sleep apnea through better data sharing. The obstructive sleep apnea is the most prevalent disorder in clinical sleep laboratories. Therefore, the main goals of the Somnolink project are (1) improvement of availability of sleep data at point of care, (2) improvement of the early diagnosis and (3) personalized therapy of OSA and (4) therapy adherence prediction.
The objectives of the project are aligned with the health data typically collected along the usual patient pathway. It consists of four stages: (1) assessing pre-test probability through medical history and questionnaires, (2) conducting physical examinations in primary care, (3) performing outpatient sleep diagnostics, and (4) carrying out comprehensive sleep laboratory studies. Based on this structure, which data are relevant at each step is identified and ML models are proposed that could assist clinicians in their decision-making ~\cite{krefting_somnolink_2025}. A central hub consisting of XNAT will manage the sleep data among the patient pathway and the AI models as a second opinion.
\begin{figure}[H]
    \centering
    \def\svgwidth{\linewidth} 
    \input{Somnolink.pdf_tex}
    \caption{Diagram: The Docker Container and the Somnolink project.}
    \label{fig:somnolink}
\end{figure}

In general, the implementation of Docker container technology is becoming increasingly prevalent within the Somnolink Project, due to it is notable that the models can be implemented with a Docker container within XNAT.
In this context, automating the Docker Container in XNAT offers a significant advantages. It allows the Somnolink predictions to be executed in a standardized manner. Such an automation not only reduces the manual intervention, but also ensures a consistent  workflow and facilitating the integration of data-driven decision support into clinical practice, which contribute to the project goals.\\
The \autoref{fig:somnolink} illustrates the structure of the OSA diagnostic pathway in relation to data collection, data driven support, and technical implementation.
The blue column shows the four steps of the German OSA patient pathway. The middle column summarizes the typical health data collected at each stage. And the last column underline the opportunity where machine learning or decision-support methods can be applied. 
The yellow banner highlights Docker container automation in XNAT  as the technical foundation that enable standardized and reproducible workflows across the steps.

\subsection{Sustainability Aspects of the Docker Container Including FAIR Criteria}
Sustainability within Somnolink project covers both the technical stability and scientific traceability. Consequently the use of the Docker Containers contribute by offering reproducible computational environments, reducing maintenance demands, and facilitating collaboration across multiple sites. However, conformity to FAIR principles strengthens the long-term reusability of the developed solutions: The Container images are well stored in the Docker Hub (Findable), they are also accessible via standardized interfaces (Accessible), employ interoperable data formats (Interoperable), and are adaptable for use in new contexts (Reusable). This harmonized approach is essential for ensuring sustainable support of the Somnolink project’s objectives. 
Another key strength for the developed automation script is its sustainability and long-term usability. The implementation is flexible and allows at the same time to the developers a reuse of the existing framework and modify only components that may need updating. Potential future changes. The Potential future changes can be :\\
- Updates to XNAT REST API endpoints.\\
- Authentication methods.\\
-  Alterations to the JSON-based format schema for command and wrapper definitions.\\
-  Docker base images in case a new better one is deprecated.\\
- XNAT project structures are extended with new contexts or data types.\\
However, the core workflow logic remains unaffected. Consequently this promote a efficient maintenance, supports sustainable software development practices.

\section{Pipeline method}
\subsection{Generalizability of the Pipeline}
\normalsize
To generalize a pipeline and to make it transferable to any user, including those limited informatics expertise, presents several challenges.
Since the method requires manual transfer of the XML descriptor,  and the available endpoints are limited. 
However, it is possible to design a template for the XML descriptor and create a Python script that collects information from the user and substitutes it into the template. Additionally, a graphical user interface (GUI) could be developed to facilitate inserting the pipeline into XNAT. However, because the REST API offers only limited functionality, such a GUI cannot fully communicate the pipeline to XNAT.



%Template für XML bauen
%\url{https://groups.google.com/g/xnat_discussion/c/nFNfCx4K2SA/m/wj8N6VtVAQAJ}
%\url{https://groups.google.com/g/xnat_discussion/c/-1LlALF1vpQ/m/APPP90ofRzAJ}
%\url{https://groups.google.com/g/xnat_discussion/c/ewhjL7upJf4/m/0Soz5-sBEzwJ}



\subsection{The Pipeline Approach and the Somnolink Project, Sustainability Aspects Including FAIR Criteria}
The pipeline approach presents challenges adhering to FAIR principles.
Pipeline descriptors are stored in locally on the XNAT server and are not systematically indexed or searchable (limited Findability).
 Accessibility is also restricted, as only administrators have the necessary permissions to manually register and configure the XML files (limited accessibility).
 Interoperability is limited because the XML descriptors are closely tied to specific XNAT data types (limited interoperability). Additionally, the potential for reuse is also limited, since adapting a pipeline to new contexts necessitates manual transfer of XML files and server access configurations (limited reusability). Within the Somnolink project, the pipeline could play a great role as workflow  facilitating the structured execution of analysis steps in the Obstructive Sleep Apnea (OSA) diagnostic. By defining a sequence of processing tasks on a manual procedure. However, the practical use of pipelines is limited, as they require direct server access and technical configuration, which makes the pipeline more suitable for developers or system administrators than for clinicians, therefore reducing the the ability of a method to be use easily across different hospitals, research centers, or clinical teams, not just by a few developers with server access.


\section{Evaluating Pipeline and Docker Approaches in XNAT}

For the purpose of evaluating the two methods, we began by compiling a comparative table to provide a clearer understanding of their respective features.

\begin{table}[H]
  \centering
  \caption{Comprehensive comparison of XNAT Pipeline method and Docker Container method.}
  \label{tab:pipeline-vs-docker}

  \begin{tabular}{|>{\centering\arraybackslash}p{2cm}|
                      >{\centering\arraybackslash}p{4cm}|
                      >{\centering\arraybackslash}p{4cm}|
                      >{\centering\arraybackslash}p{4cm}|}
    \hline
    \textbf{Aspect} & \textbf{The Pipeline method} & \textbf{Docker Container method} & \textbf{Automatization of the Docker method}\\ \hline
    
    
    Installation & Requires manual placement of XML descriptors, plugin JARs\footnote{\url{https://wiki.xnat.org/documentation/installing-the-pipeline-engine} last accessed 07.10.2025}, and executables on the server. & Container image uploaded once (via Docker registry) and configured in XNAT. & The automatization script must be launched and the Docker Engine must be installed and started up as well. \\ \hline
    

    
    Configuration & Admin must edit data types, enable actions, and rebuild Pipeline engine, require direct access to the server in order to manually copy the XML descriptor and associated scripts to a specific directory. & Minimal configuration through a JSON command, no engine rebuild needed. & No need for any configuration, the script carries the workflow to the end. \\ \hline
    
    Execution & The Run Pipeline option must be built via actions menu. & Triggered via actions menu or REST API, image runs in isolated environment. & The Docker Container is enabled automatically sitewide and project wide too. \\ \hline

    Deployability and flexibility & Pipelines are highly dependent on the specific XNAT environment and server configuration in which they are deployed. & Docker images can be reused in various XNAT installations and environment. & Automatically deploying within XNAT, after that the images can be reused in different environment. \\ \hline
    
    Maintenance & Requires server access and manual reconfiguration. & Updating requires building and pushing a new image, no direct server changes needed. & Old image can be deleted and then creating new images with updated external script.\\ \hline
    
    Usability & Requires XML schema knowledge and direct server administration. & Requires Docker knowledge, but easier to reuse prebuilt images, through running basic commands on terminal. & Extreme low knowledge requirement (except writing a requirement file and answering the script questions. \\ \hline
    
    Consistency & Depends on identical server setups and configurations. & High reproducibility is achieved, as all dependencies are within the container. & All dependencies are within the container, since the user has written the requirement file separately. \\ \hline
    
    Community & Limited documentation and less support from XNAT Community. & Huge support from XNAT community. & Big support of the REST API. \\ \hline
    
    Security & Credentials needed in XML configuration. & Isolated container environments. & Isolated container environments. \\ \hline
  \end{tabular}
\end{table}

 The table \ref{tab:pipeline-vs-docker} has been added to present a direct comparison between the two methods.




 
 \subsection{Advantages and Disadvantages of the Methods}

After comparing both approaches in terms of installation, configuration, automation, and maintenance (see ~\autoref{tab:pipeline-vs-docker}), a summary of their main advantages and disadvantages is provided in ~\autoref{tab:docker_pipeline}.

\begin{table}[htbp]
\centering
\caption{Advantages and disadvantages of the Pipeline method and Docker Container method in XNAT.}
\label{tab:adv-disadv}
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{|p{3cm}|p{3cm}|p{5cm}|p{4cm}|}
\hline
\textbf{Aspect} & \textbf{Pipeline Method} & \textbf{Docker Container Method} & \textbf{Automatization of the Docker method} \\
\hline
\textbf{Advantages} &
\parbox[t]{3cm}{
- Fully compatible with older XNAT versions\footnote{\url{https://wiki.xnat.org/documentation/xnat-1-7-5-3-release-notes} last accessed 28.09.2025}.\\
- Can execute external applications and shell scripts~\cite{jansen_extending_2015}.
}
&
\parbox[t]{5cm}{
- Easy installation (Docker Engine). \\
- Minimal configuration via JSON-based command.\\
- Highly reusable across XNAT servers. \\
- Easier updates by building and pushing a new image. \\
- Large community support.\\
- Secure via isolated container environment. \\
- Docker images stored on Docker Hub can be used in different clinics and research institutions.\\
}
&
\parbox[t]{4cm}{
- No configuration needed. \\
- Extremely low knowledge requirement (only need to write a requirements file). \\
- All manual steps automated. \\
- The script asks simple questions. \\
- Time saving compared to the manual Docker method. \\
- Images reusable across environments and institutes. \\
- Images securely stored in Docker Hub and within XNAT.\\
} \\
\hline
\textbf{Disadvantages} &
\parbox[t]{3cm}{
- Requires manual placement of XML descriptors.\\
- Needs server access for installation and updates.\\
- Requires XML schema knowledge.\\
- Limited automation support and no automation achievable.\\
}
&
\parbox[t]{6cm}{
- Requires Docker knowledge. \\
- Depends on Docker availability \\if Docker is blocked or fails, \\images are not recognized\\ within XNAT. \\
- Requires regular expression\\ knowledge for file filtering. \\
- Limited access to the database. \\
- Mounting extracted files \\ consumes significant \\storage space.\\
}
&
\parbox[t]{4cm}{
- Works better with launching multiple containers. \\
- Problems launching a single container. \\
- For specific file processing, the JSON command in the script must be adjusted with an extra matcher.
} \\
\hline
\end{tabular}
\label{tab:docker_pipeline}
\end{table}


\section{Measures for the Future for both Methods}

The Docker Container method is determined to be better than the Pipeline method, as shown in the table above the Docker Container is a simplified and secure method.  
The Docker Container method offers significant advantages over the Pipeline method in XNAT.
Almost all the steps of the Docker Container are simplified and requiring minimal steps compared to the Pipeline method. Furthermore it provides a better automation through the REST API support.  Furthermore, Docker's usability is improved with prebuilt image reusability, high reproducibility, strong community support, and enhanced security through isolated container environments, ultimately making it a more efficient and manageable solution.

Looking ahead, both methods have potential for future development.\\
For the Pipeline method, future development should focus on two key areas: Firstly, establishing a secure pipeline Hub to centralize storage and enhance environmental security. Secondly, integrating XML deployment directly within XNAT would streamline the build process for the "Run Pipeline" option, eliminating the need for server access and simplifying overall usability.\\
Future development of the Docker Container method should focus on: Firstly, enabling direct access to the XNAT database to facilitate comprehensive file processing across the entire project. Secondly, enhancing the JSON command to allow re-uploading processed files to various output locations within XNAT, regardless of the initial file selection. This would ensure that processed files are returned to their original locations, streamlining data management and improving workflow efficiency.
