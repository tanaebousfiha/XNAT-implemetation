\chapter{The Analysis of the First Method: Docker Container}

\section{Introduction to the Automation Script for the Docker Container Method}
The first method analyzed was the Docker Container, and after reviewed the last points supported by XNAT Community, a review of the latest updates from the XNAT Community indicated that automation of Docker container implementation is feasible.

\section{Table of the REST API in the Script}

In order to summarize all the REST API needed in the script, a summarizing table was created.

\begin{longtable}{|l|p{0.4\textwidth}|p{0.4\textwidth}|}
    \hline
    \textbf{Method} & \textbf{Endpoint} & \textbf{Purpose} \\
    \hline
    \endfirsthead

    \hline
    \textbf{Method} & \textbf{Endpoint} & \textbf{Purpose} \\
    \hline
    \endhead

    POST & \path{/xapi/commands} & Upload a Command (JSON) \\
    \hline
    GET  & \path{/xapi/commands} & List all the commands to get the wrapper ID and the command ID \\
    \hline
    PUT  & \path{/xapi/commands/{command_id}/wrappers/{wrapper}/enabled} & Enable wrapper site-wide \\
    \hline
    POST & \path{/xapi/projects/{project_id}/commands/{command_id}/wrappers/{wrapper}/root/project/launch} & Launch container wrapper in project context \\
    \hline
    GET  & \path{/data/projects/{project_id}/resources?format=json} & List all project resources \\
    \hline
    GET  & \path{/data/projects/{project_id}/resources/{resource_label}/files?format=json} & List files inside a project resource \\
    \hline
    GET  & \path{/data/projects/{project_id}/subjects?format=json} & List all subjects in a project \\
    \hline
    GET  & \path{/data/subjects/{subject_id}/resources?format=json} & List subject-level resources \\
    \hline
    GET  & \path{/data/subjects/{subject_id}/resources/{resource_label}/files?format=json} & List files inside a subject resource \\
    \hline
         & \path{/data/subjects/{subject_id}/resources/{resource_label}/files/{file_name}} & Direct file path (download or reference) \\
    \hline
    GET  & \path{/data/projects/{project_id}/experiments?format=json} & List sessions (experiments) in a project \\
    \hline
    GET  & \path{/data/experiments/{experiment_id}/resources?format=json} & List session-level resources \\
    \hline
    GET  & \path{/data/experiments/{experiment_id}/resources/{resource_label}/files?format=json} & List files in a session resource \\
    \hline
         & \path{/data/experiments/{experiment_id}/resources/{resource_label}/files/{file_name}} & Direct file path (download or reference) \\
    \hline
    GET  & \path{/data/experiments/{experiment_id}/scans?format=json} & List scans within a session \\
    \hline
    GET  & \path{/data/experiments/{experiment_id}/scans/{scan_id}/resources?format=json} & List scan-level resources \\
    \hline
    GET  & \path{/data/experiments/{experiment_id}/scans/{scan_id}/resources/{resource_label}/files?format=json} & List files inside a scan resource \\
    \hline
      
\end{longtable}


The REST API is a sort of backbone of the automatization in XNAT workflow, it assures a orchestration of the container execution, and at the same time assuring  traceability and reproducibility. The REST API played a crucial role to develop a automatic workflow in the XNAT platform. The figure 3.1 illustrates the role of the REST API in the automatization


\begin{figure}[ht]
    \centering
    \def\svgwidth{0.9\linewidth}
    \input{RESTAPI.pdf_tex}
    \caption{Diagram: illustrates the role of the REST API in the automatization}
    \label{fig:workflow-steps}
\end{figure}














\section{The Automation Script}
The purpose of this chapter is to introduce the system in more detail. A Python script is used to combine all the steps into an automated workflow. The libraries used in this work include: \texttt{requests}\footnote{\url{https://www.w3schools.com/python/module_requests.asp} accessed on 10 August 2025}, \texttt{json}\footnote{\url{https://www.w3schools.com/python/python_json.asp} accessed on 10 August 2025}, \texttt{os}\footnote{\url{https://docs.python.org/3/library/os.html} accessed on 10 August 2025}, \texttt{subprocess}\footnote{\url{https://docs.python.org/3/library/subprocess.html} accessed on 10 August 2025}, \texttt{getpass}\footnote{\url{https://docs.python.org/3/library/getpass.html} accessed on 10 August 2025}, \texttt{sys}\footnote{\url{https://docs.python.org/3/library/sys.html} accessed on 10 August 2025}, and \texttt{urllib3}\footnote{\url{https://urllib3.readthedocs.io/en/stable/} accessed on 10 August 2025}.

The use of the Requests library was for creating the interaction with the web services of XNAT. The Python Requests library is the go-to solution for making HTTP requests in Python, thanks to its elegant and intuitive API that simplifies the process of interacting with web services and consuming data in the application.\footnote{\url{https://www.datacamp.com/tutorial/python-subprocess} accessed on 10 August 2025} The Sys module in Python provides access to variables and functions that interact closely with the Python interpreter and runtime environment.

Since a JSON command is written, the use of the JSON library was necessary. JSON is a syntax for storing and exchanging data. It is text, written with JavaScript Object Notation.\footnote{W3Schools, Python JSON}
The Python Subprocess module is a tool that allows running other programs or commands from your Python code. Using the Python Subprocess module resembles executing commands directly on the system computer using Python instead of typing them directly into the command prompt. This module makes it easy to automate Python code.\footnote{\url{https://www.datacamp.com/tutorial/python-subprocess} accessed on 10 August 2025}
Getpass() prompts the user for a password without echoing. The getpass module provides a secure way to handle password prompts where programs interact with the users via the terminal.\footnote{\url{https://www.geeksforgeeks.org/python/getpass-and-getuser-in-python-password-without-echo/} accessed on 10 August 2025}

The urllib3 library was used to disable the InsecureRequestWarning, which is normally shown when Requests connects to a site with an unverified SSL certificate. This approach helps keep the output clean and free of unnecessary warnings during the run of the script.

Currently, the system is running Docker Engine 28.3.0. The Docker Client version in use is 20.10.5+dfsg1, which communicates with the Docker Engine to issue commands and manage images and containers. The XNAT web application is running on version 1.9.1.1, as verified through the web interface.


\begin{figure}[ht]
  \centering
  \def\svgwidth{0.8\linewidth}
  \input{lib.pdf_tex}
  \caption{Schema: Core Libraries for Python Scripting in System Integration}
  \label{fig:diagram-core-libraries}
\end{figure}





\section{Architecture and organization of the Code}
The automation script is structured into 17 distinct parts, each one responsible for a specific step in the overall workflow.
During the development of the automation script, I closely followed the steps of the manual process, since I had already tested and completed it manually. This included writing a container script, writing a Dockerfile, building the image, writing a JSON command, and enabling the command first on the website and then on the project, with the last step being the launch of the container. I carefully repeated the same steps during the implementation. In other words, every structured part is composed of a function that is responsible for carrying out a step of the manual process.
 
 \section{The Dockerfile}
 
The first function responsible for writing the Dockerfile is called \texttt{def write\_dockerfile}, and it takes three arguments: the target directory for the Dockerfile, the name of the Python script to include, and an optional base Docker image (defaulting to \texttt{python:3.10-slim}, currently the fastest and slimmest image of Docker). The function creates the necessary folder (if it does not already exist), constructs the Dockerfile content, and writes it. The content of the Dockerfile is introduced with string interpolation and contains the base image and several commands such as \texttt{WORKDIR /app} (a working directory) and \texttt{COPY \{script\_filename\} /app/\{script\_filename\}} to copy the user script inside the image. The line \texttt{RUN pip install --no-cache-dir pandas} tells Docker to install the pandas Python library using pip during the build process of the Docker image, which helps reduce the overall image size and avoids unnecessary layers in the build process. The last component of the Dockerfile is \texttt{COPY requirements.txt /app/requirements.txt}, which provides the opportunity for the user to write in a separate text file all the libraries used in the container script, to be installed later during the image build process.


The \texttt{CMD} instruction was removed from the Dockerfile because it caused errors when running the container in XNAT. The issue was due to a conflict between the \texttt{CMD} instruction in the Dockerfile and the JSON command configuration, as both included the \texttt{python3} prefix. This led to a duplicate command execution, which caused the container to fail. By removing \texttt{CMD} from the Dockerfile, the execution logic is now fully controlled by XNAT through the JSON command, ensuring a successful launch of the container.

\begin{lstlisting}[language=bash,caption={Dockerfile}]
FROM python:3.10-slim
WORKDIR /app
COPY script.py /app/script.py
RUN pip install --no-cache-dir pandas
COPY requirements.txt /app/requirements.txt
\end{lstlisting}

The rest of the \texttt{def write\_dockerfile} ensures that the specified directory exists, then creates and writes a Dockerfile to that location. It constructs the full path to the file, writes the generated content into it, and prints a confirmation message.


\lstset{
  language=Python,
  basicstyle=\ttfamily\small\color{black},
  keywordstyle=\color{black},
  identifierstyle=\color{black},
  stringstyle=\color{black},
  commentstyle=\color{black},
  numberstyle=\color{black},
  showstringspaces=false
}

\begin{lstlisting}
os.makedirs(docker_dir, exist_ok=True)
dockerfile_path = os.path.join(docker_dir, "Dockerfile")
with open(dockerfile_path, "w") as f:
    f.write(dockerfile_content)
print(f"Dockerfile written to {dockerfile_path}")
return dockerfile_path
\end{lstlisting}

This function ensures that the Dockerfile is written in an appropriate way and secures that all the dependencies are stored in the external requirements text file. It handles all possible cases and avoids the issues of errors and standard input errors.

\section{Building, Pushing and Tagging the Image}

When a command is deployed in XNAT and a container is launched, the first thing that XNAT checks is whether the Docker image is available in DockerHub. This means the user must have an account in DockerHub and preferably log in before using the following script. Consequently, it is essential to push and tag the created image.

The function responsible for the build is \texttt{def build\_docker\_image}, and it expects two parameters: \texttt{dockerfile\_path} for the Dockerfile path and the name/tag for the Docker image to be built \texttt{docker\_image\_name}. For the build, we used \texttt{subprocess.run} to call the external \texttt{docker build} command.


Usually, when we want to build an image in Docker, we use the basic command \texttt{docker build .}

\begin{lstlisting}
full_tag = f"{dockerhub_username}/{docker_image_name}"
    print(f"Building Docker image '{full_tag}'...")
    build_result = subprocess.run(
        ["docker", "build", "-f", dockerfile_path, "-t", full_tag, "."],
        capture_output=True, text=True)
    if build_result.returncode != 0:
        print(f"Build failed:\n{build_result.stderr}")
        sys.exit(1)
    print(f"Image '{full_tag}' built successfully.")
\end{lstlisting}
As we can see in this block, \texttt{subprocess.run} was used to call the external \texttt{docker build} command, and the \texttt{-f dockerfile\_path} option tells Docker which Dockerfile to use. The \texttt{-t docker\_image\_name} option sets the name and tag for the image. The point (.) at the end of the command means the current directory will be used as the build context. In addition, \texttt{capture\_output=True} collects both stdout and stderr so the script can handle their output or errors, and \texttt{text=True} ensures that outputs are returned as strings.

Now that the image has been successfully built and tagged, we can proceed to the next essential step: pushing the image to Docker Hub. To do this, the same method of \texttt{subprocess.run} is used.


\begin{lstlisting}
    push_result = subprocess.run(["docker", "push", full_tag], capture_output=True, text=True)
    if push_result.returncode != 0:
        print(f"Push failed:\n{push_result.stderr}")
        sys.exit(1)

    print(f"Image successfully pushed: {full_tag}")
    return full_tag
\end{lstlisting}

In normal cases, we use the command \texttt{docker push image\_name}, and this assumes that the user is already logged in to their Docker account. However, in the automation script, we make use of \texttt{subprocess.run}.

To explain this block, we begin by discussing the reason for using the full image tag. It constructs a complete image tag in the Docker Hub format. Since Docker Hub requires image tags to follow a specific structure, the full image tag uses the format \texttt{dockerhub\_username/image\_name[:tag]}.

This line creates a correctly formatted name for the Docker image, linking the Docker Hub account \texttt{(dockerhub\_username)} with the chosen image name and optional version tag \texttt{(docker\_image\_name)}.

The line of the code: 
\begin{lstlisting}
push_result = subprocess.run(["docker", "push", full_tag], capture_output=True, text=True)
\end{lstlisting}
refers to the push process with the \texttt{subprocess.run} method. And it follows the same concept as building the Docker image.

\section{The Prompt Function for the Required Input}

This function performs the task of capturing input from the user.
We have used this function in the script in multiple scenarios. The first was to take the Docker Hub username from the user. To customize the JSON command, we asked the user for the name of the command and its description. Overall, it is also used to take the username and password from the user’s login credentials. The function proceeds through all of these steps while running the script.

The function looks like this:
 
 \begin{lstlisting}
 def get_input(prompt):
    while True:
        value = input(prompt)
        if value.strip():
            return value
        else:
            print("Cannot be empty.")

\end{lstlisting}
The \texttt{def get\_input} function uses a \texttt{while True} loop to keep asking until the user enters input. The \texttt{value.strip()} removes any whitespace from the user input. If the input is valid, the value is returned; if not, the message \texttt{Cannot be empty} will be printed.

\section{The JSON Command}

To communicate the Docker image to XNAT, and consequently to run the container in the website, it is necessary to write a JSON command.\footnote{\url{https://wiki.xnat.org/container-service/json-command-definition}}
Usually, the JSON command is personalized and customized depending on the main idea of the image. But in the automation case, the JSON command must be generalized for all cases, which means no matter which file is selected, the command will still handle it.

To achieve that, the function used is called \texttt{create\_json\_file}, which builds the configuration dictionary for a Docker-based XNAT command (for the XNAT Container Service), writes it to a \texttt{command.json} file, and returns the filename.

The function expects three parameters:

\texttt{docker\_image}: The Docker image to use (string).

\texttt{script\_filename}: The name of the Python script inside the container (string).

\texttt{mod\_data}: A dictionary holding user-provided metadata (names, descriptions, etc.).

Let us start analyzing the first block of the JSON command:
\begin{lstlisting}

json_file = {
        "name": mod_data["command_name"],
        "description": mod_data["command_description"],
        "version": "1.5",
        "type": "docker",
        "image": docker_image,
        "command-line": f"python3 /app/{script_filename} /input/#input_file# /output",
        "mounts": [
            {"name": "input", "path": "/input", "writable": False},
            {"name": "output", "path": "/output", "writable": True}
        ],
\end{lstlisting}


In this block, we are defining the name of the command, adding a description, and specifying the version and the type of the image.
The command line declares the actual command to run inside the container when invoked by XNAT. The placeholder \# is a template substitution (not a regex expression) that tells XNAT: \texttt{"When you launch the Docker command, replace \#input\_file\# with the actual file name/path that the user selected as input."} It does not define what a valid file looks like; instead, it marks a spot in the command where XNAT should "fill in" an actual value.


The mount configures the directory mappings (as Docker volumes) between XNAT and the Docker container. Most of the time, two are used: the input and the output.
We specified the path \texttt{/input} in the container and indicated whether the container can only read the files (\texttt{Not writable}) or can also write them (\texttt{Writable}).

The second part of the JSON command:


\begin{lstlisting}

 "inputs": [
            {
                "name": "input_files",
                "description": "Input files",
                "type": "files",
                "element_type": "file",
                "required": True,
                "mount": "input",
                "multiple": True
            }
        ],
        "outputs": [
            {
                "name": "result_file",
                "type": "file",
                "description": "Result file output",
                "mount": "output",
                "path": "."
            }
        ],
\end{lstlisting}


This block defines the parameters that a user must provide as an input file when launching the container.
Let’s break down each field:

The \texttt{"name": "input\_files"} is used in other parts of the JSON as a reference---such as placeholders in the command line. In addition, we add an optional human-friendly description. The \texttt{"type"} indicates that the input accepts more than just text files, scans, or numbers; it specifies that each element in the input is specifically a file through the \texttt{"element"} field.

The \texttt{"required": true} flag means that if the input is not provided, the command cannot be run. The mount in this part links the input to a specific mount inside the container. All files provided by the user will appear in the \texttt{/input} directory inside the container. With \texttt{"multiple": true}, it is indicated that the user can upload or select more than one file for this input.

The same logic applies to the output part. The only additional point to note is the \texttt{"path": "."}, which means the output file will be placed at the top level of the \texttt{/output} directory. To allow more than one output file, the setting \texttt{"type": "files"} is used in the output block.

The final block in the JSON command:

\begin{lstlisting}

 "xnat": [
            {
                "name": wrapper_name,
                "label": mod_data["label_name"],
                "description": mod_data["label_description"],
                "contexts": ["xnat:projectData"],  
                "external-inputs": [
                    { 
                        "name": "project",
                        "type": "Project",
                        "required": True,
                        "load-children": True
                    }
                ],
                "output-handlers": [
                    {
                        "name": "output",
                        "accepts-command-output": "result_file",
                        "as-a-child-of": "project",
                        "type": "Resource",
                        "label": "Results",
                    }
\end{lstlisting}

This block defines what will be displayed on the XNAT interface and connects the Docker command with XNAT's web interface and permission system. It controls how the command appears as a tool in XNAT, how it is integrated with projects or other data, and how inputs are handled.

The wrapper name is the technical name of the command inside XNAT. The \texttt{"label": mod\_data["label\_name"]} is a human-readable name shown in the XNAT \ac{UI}. The \texttt{"description": mod\_data["label\_description"]} is a description for the tool/wrapper, shown when users browse tools in XNAT. The \texttt{"context"} specifies where we want the container to appear in the XNAT interface. Since the main idea was to have one container on top of the structure of XNAT, here \texttt{["xnat:projectData"]} means this command is available at the project level.


In the \texttt{"external-input"} block, external entities from XNAT are defined. Because we used the project as the context for the command, we require in the external input that a project be selected. In more detail, the name and type must be "Project." This input must be provided, which is why \texttt{"required": true} is specified. We tell XNAT with \texttt{"load-children": true} to load (in the UI) the child objects of the project when showing this input.

In the \texttt{"output-handlers"} block, we control how the outputs from the command are stored and shown in XNAT after job completion. This output handler tells XNAT to take the result file produced by the command, store it as a resource under the project, and call that section ``Results'' in the UI. The \texttt{"as-a-child-of": "project"} specifies that the results are uploaded back into the XNAT project as new resources.

Finally, the script writes the JSON command file, ensuring that the JSON command is saved in the correct format, ready to be uploaded to XNAT.

\section{Upload the Command in XNAT}

After writing the JSON command, the next step is to send it to XNAT. To achieve this, we have to use the appropriate REST API responsible for uploading the container command to XNAT.
We can find the list of all REST APIs under \texttt{Administer $\rightarrow$ Site Administration $\rightarrow$ Miscellaneous $\rightarrow$ Development Utilities $\rightarrow$ Swagger}.
To send the command to XNAT, we found that the responsible REST API is \texttt{POST}.\footnote{\url{https://xnat-dev.gwdg.de/xapi/swagger-ui.html\#/command-rest-api}}

The function responsible for this is \texttt{def send\_json\_to\_xnat}, and it expects four parameters: \texttt{json\_file\_path, xnat\_url, xnat\_user, xnat\_password}. When working with REST APIs, we first have to build the URL endpoint for XNAT’s command registration.
 
\begin{lstlisting}
def send_json_to_xnat(json_file_path, xnat_url, xnat_user, xnat_password): 

    url = f"{xnat_url}/xapi/commands"
    print(f"Uploading command to {url}")
    with open(json_file_path, "r") as f:
        response = requests.post(url, auth=(xnat_user, xnat_password), json=json.load(f))
    if response.status_code == 200:
        print("Command uploaded successfully.")
    elif response.status_code == 201:
        print("Command created successfully.")
    elif response.status_code == 409:
        print("Command already exists.")
    else:
        print(f"Failed to upload command: {response.status_code} - {response.text}")
\end{lstlisting}

This function takes the path that describes the JSON command, the base URL of the XNAT server, and the credentials for authentication. First, it constructs the correct REST API endpoint by appending \texttt{/xapi/commands} to the provided XNAT URL, ensuring that the command is sent to the appropriate API for command registration. It then opens the JSON file, loads its contents, and sends this data as a POST request to the API endpoint using \ac{HTTP} Basic Authentication with the supplied username and password. After making the request, the function examines the server’s response, and in each case provides feedback, helping the user quickly understand whether the command upload succeeded or if further action is needed to resolve an issue.

\section{Preparations to Launch the Container}

The goal of the previous steps is to launch the container in XNAT, but before that we need to perform some preparations. In line with the automation principle, we need to retrieve some information from the XNAT web service, and in this case we use the REST API technique as well. The first information that we need to extract after sending the JSON command to XNAT is the \texttt{Command ID} and the \texttt{Wrapper ID}.
In order to do that...
 
\begin{lstlisting}
def get_command_wrapper_id(xnat_host, xnat_user, xnat_password, command_name, wrapper_name=None):
 
    url = f"{xnat_host.rstrip('/')}/xapi/commands"
    try:
        resp = requests.get(url, auth=(xnat_user, xnat_password), verify=False)
    except Exception as e:
        print(f"Verbindungsfehler: {e}")
        sys.exit(1)
    if resp.status_code != 200:
        print(f"Fehler beim Abrufen der Commands: {resp.status_code}")
        sys.exit(1)
    data = resp.json()
    commands = data.get("commands", data) if isinstance(data, dict) else data

    for command in commands:
        if command.get("name") == command_name:
            if not wrapper_name:
                return command.get("id")
            
            for wrappers_field in ["xnat", "wrappers"]:
                for wrapper in command.get(wrappers_field, []):
                    if wrapper.get("name") == wrapper_name:
                        return wrapper.get("id") or wrapper_name
            print("no Wrapper found")
            sys.exit(1)
    print("Command nicht gefunden.")
    sys.exit(1)
\end{lstlisting}

The function takes as input the XNAT server’s hostname, user password, the name of the desired command, and the name of a specific wrapper. It first builds the correct XNAT REST API endpoint to list all the registered commands on XNAT.
Upon receiving a response, the function checks for a successful status (200 OK); otherwise, it reports the failure and exits. If only a command ID is needed (no wrapper specified), it returns the command’s ID directly. If a wrapper name is provided, the function searches for the wrapper within possible sections of the command definition under XNAT or the \texttt{"wrappers"} fields—returning the wrapper’s ID upon match. If the specified command or wrapper cannot be found, the function clearly reports this to the user.

After receiving the Command ID and the Wrapper ID, we proceed by enabling the command in the project and site-wide. For that, we use the two functions \texttt{def enable\_wrapper\_sitewide} and \texttt{def enable\_wrapper\_for\_project}, which both expect parameters such as the server’s hostname, user login and password, and the extracted Command ID and Wrapper ID. Each function builds the desired XNAT REST API endpoint (in this case, we used the \texttt{PUT} REST API), checks the status of the process, and provides feedback to the user to track the code’s progress.

\section{The Extraction of All Files from All Project Structures}

The function used in this part is \texttt{def get\_all\_files\_all\_levels}, and it collects all the files in the project data hierarchy (project, subjects, experiments/sessions, and scans) from an XNAT system using its REST API. We used the REST API endpoint \texttt{GET} for the extraction. The function proceeds by authenticating with the XNAT server using the provided user credentials and starts by gathering project-level files, querying all resource folders at the project root and listing every file found within them. At every step, the function structures each file into a dictionary containing hierarchical information (such as the level—project, subject, experiment, scan—and the relevant IDs), the file name, the resource folder it was found in, and an absolute URI for straightforward retrieval. By the end, it returns a comprehensive list of all file records across all levels in the project.
\begin{figure}[ht]
    \centering
    \def\svgwidth{0.9\linewidth}
    \input{extraction.pdf_tex}
    \caption{Diagram: The Extraction of files from all the project structure}
    \label{fig:enter-label}
\end{figure}

\section{Launch the Container}

Arriving at the well-known part of launching the container, we use the function \texttt{def launch\_container\_with\_all\_files}. This function is designed to automatically launch a container with all the files previously extracted as input. It takes the XNAT server connection details, project and command identifiers, user authentication, the wrapper name, and a list of files to be processed.

The function first checks if any files are provided. A payload dictionary is then prepared, mapping the project ID and the input files string to the fields. Next, the function constructs the appropriate URL for launching the command. Before sending the launch request, the function prints diagnostic information, including the chosen files and payload. It then submits a \texttt{POST} request with the payload as JSON and user credentials for authentication. After sending the request, the function reports back to the user about the status and the response.

\begin{lstlisting}
def launch_container_with_all_files(xnat_host, project_id, command_id, wrapper_name, xnat_user, xnat_password, files):
   
    if not files:
        print("no files found.")
        return 

    payload = {
        "project": project_id,
        "input_files": input_files_str
    }

    url = f"{xnat_host}/xapi/projects/{project_id}/commands/{command_id}/wrappers/{wrapper_name}/root/project/launch"

    headers = {"Content-Type": "application/json"}
    response = requests.post(
        url, auth=(xnat_user, xnat_password),
        headers=headers, json=payload, verify=False
    )

    print("Status:", response.status_code)
    print("Antwort:", response.text)
    if response.status_code in [200, 201, 202]:
        print("Container launched with all files!")
    else:
        print("failure :", response.status_code, response.text)
\end{lstlisting}

\begin{figure}[ht]
    \centering
    \def\svgwidth{0.9\linewidth}
    \input{steps.pdf_tex}
    \caption{Diagram: Workflow Steps for the Implementation}
    \label{fig:workflow-steps}
\end{figure}

The figure illustrates how the automation script facilitates the process of deploying a container in XNAT. It reduces all the steps.

\begin{figure}[ht]
    \centering
    \def\svgwidth{0.9\linewidth}
    \input{compare.pdf_tex}
    \caption{Diagram: Diagram illustrating the difference between the manual and the automatic process}
    \label{fig:enter-label}
\end{figure}

\begin{comment}
    https://wiki.xnat.org/documentation/strategies-for-xnat-image-data-storage
\end{comment}


\section{Testing the Code}
After testing the code, we can see in the beginning \texttt{see the Appendix at the end}, the process actively requests input from the user in order to proceed with the implementation. It started by asking the user for login credentials, then the Project ID that the user wants to process, and lastly, before proceeding with the creation and command sending to XNAT, it asked the user about the command name and the description.
After receiving all the information, the script commenced building the image, tagging, pushing, writing the JSON command, enabling the command, and lastly launching the container with all files.

\section{Results on XNAT}
The result that we came to after testing the code is that all the steps are working correctly, except that the container could not receive any files. With the \ac{STDout} view we found out that the container received zero files. 
 
\begin{lstlisting}[numbers=none]
View stdout (from file)
Inhalt von /input (rekursiv):
/input: []
Keine CSV-Datei in /input gefunden.
\end{lstlisting}


But interestingly, after searching in the container information, we noticed that the container in fact received the files and that the files are listed in the input part of the container input. 
Details of the test procedure are described in Appendix A \cite{bousfiha2025appendix}.

The results demonstrate two things. First, the automation script with the REST API worked correctly. Second, there is an issue with the container accessing the input files, despite them being listed as received.
\begin{chapter}

This chapter presents an overview of the implementation solution, the technical challenges encountered during integration with XNAT, and the methods employed to overcome the issues. Several problems emerged throughout development, including data transmission failures, REST API inconsistencies, and JSON configuration mismatches.

The initial problem was that the container did not appear to receive any input files. To confirm this, a test was performed by adding a script within the container. The script was designed to write a file named \texttt{no\_file.txt} if no input file was detected at runtime. The successful upload of this file confirmed that while the container was running, it was not receiving actual input data.

Following the initial diagnosis, another test was conducted. Efforts were made to use the integration of the REST API within the container to retrieve files, process them, and upload the results. Despite the API being correctly called, no file results appeared in XNAT. 

Attention then shifted to the JSON command that defines the container command structure in XNAT. The JSON command was enhanced to include login credentials and more detailed output specifications. Multiple versions were tested, each with different contexts. Despite these efforts, no successful uploads occurred, and in some cases, the command itself was rejected by XNAT. 

It was hypothesized that the container execution timing could play a role in the failure. To test this, the automation script was modified to introduce a 10-second delay between each container execution. The assumption was that the host system might be under resource pressure when running multiple containers in rapid succession. However, introducing delays did not resolve the core issue: the container still did not receive input files.
%-------------------------------------------------------------------------------------------------------------------------

\section{The Workflow Data in XNAT}

In most cases, when we press the button \textit{Run Container} in XNAT manually, the data is automatically provided, and the container handles the data and reloads the results back into the system.  
In detail, when the container is launched, the platform orchestrates a series of data management and processing steps to facilitate the workflow. At first, the system generates a JSON specification. This specification includes information about the script and command line to be executed, the output file location, and the container input, ensuring that the containerized process has access to all relevant instructions.  
Furthermore, XNAT identifies the relevant data and prepares it for transfer to the designated computational environment. The data is then mounted or copied to a temporary directory within the host system, ensuring accessibility for the containerized analysis. Once the container is activated, it processes the input data according to the command-line script, generates the output data, and finally writes the output back to the designated result directory on the host.  

Assuming that the container has the ability to process a large number of files, there is also the possibility to increase the number of files that can be handled using the command \texttt{ulimit}.  
The fact that XNAT mounts or copies the data to a temporary directory within the host system reveals important insights into the underlying problem. Copying the data to the host system and mounting it into a volume means that the container has no direct access to the XNAT database, which can potentially lead to issues related to memory or disk space on the host. This approach may result in resource constraints.  
This issue can become particularly problematic when large datasets are involved. Although my specific test case involved a relatively small number of files, the container still failed to process the data successfully. This suggests that the problem may not be solely related to dataset size or resource limits.

The diagram below illustrates the workflow data for a clearer understanding.  

\begin{figure}[ht]
    \centering
    \def\svgwidth{\linewidth} 
    \input{xnat.pdf_tex}
    \caption{Diagram: XNAT Workflow for Container Integration}
    \label{fig:workflowxnat}
\end{figure}

\end{chapter}