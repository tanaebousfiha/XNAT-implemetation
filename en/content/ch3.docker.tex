\chapter{The Analysis of the First Method: Docker Container}

\section{Introduction to the Automation Script for the Docker Container Method}
The first method analyzed was the Docker Container, and after reviewed the last points supported by XNAT Community, a review of the latest updates from the XNAT Community indicated that automation of Docker Container deployment in XNAT is feasible.

\section{Table of the REST API in the Script}

In order to summarize all the REST API needed in the script, a summarizing table was created.

\begin{longtable}{|l|p{0.4\textwidth}|p{0.4\textwidth}|}
    \hline
    \textbf{Method} & \textbf{Endpoint} & \textbf{Purpose} \\
    \hline
    \endfirsthead

    \hline
    \textbf{Method} & \textbf{Endpoint} & \textbf{Purpose} \\
    \hline
    \endhead

    POST & \path{/xapi/commands} & Upload a Command (JSON) \\
    \hline
    GET  & \path{/xapi/commands} & List all the commands to get the wrapper ID and the command ID \\
    \hline
    PUT  & \path{/xapi/commands/{command_id}/wrappers/{wrapper}/enabled} & Enable wrapper site-wide \\
    \hline
    POST & \path{/xapi/projects/{project_id}/commands/{command_id}/wrappers/{wrapper}/root/project/launch} & Launch container wrapper in project context \\
    \hline
    GET  & \path{/data/projects/{project_id}/resources?format=json} & List all project resources \\
    \hline
    GET  & \path{/data/projects/{project_id}/resources/{resource_label}/files?format=json} & List files inside a project resource \\
    \hline
    GET  & \path{/data/projects/{project_id}/subjects?format=json} & List all subjects in a project \\
    \hline
    GET  & \path{/data/subjects/{subject_id}/resources?format=json} & List subject-level resources \\
    \hline
    GET  & \path{/data/subjects/{subject_id}/resources/{resource_label}/files?format=json} & List files inside a subject resource \\
    \hline
         & \path{/data/subjects/{subject_id}/resources/{resource_label}/files/{file_name}} & Direct file path (download or reference) \\
    \hline
    GET  & \path{/data/projects/{project_id}/experiments?format=json} & List sessions (experiments) in a project \\
    \hline
    GET  & \path{/data/experiments/{experiment_id}/resources?format=json} & List session-level resources \\
    \hline
    GET  & \path{/data/experiments/{experiment_id}/resources/{resource_label}/files?format=json} & List files in a session resource \\
    \hline
         & \path{/data/experiments/{experiment_id}/resources/{resource_label}/files/{file_name}} & Direct file path (download or reference) \\
    \hline
    GET  & \path{/data/experiments/{experiment_id}/scans?format=json} & List scans within a session \\
    \hline
    GET  & \path{/data/experiments/{experiment_id}/scans/{scan_id}/resources?format=json} & List scan-level resources \\
    \hline
    GET  & \path{/data/experiments/{experiment_id}/scans/{scan_id}/resources/{resource_label}/files?format=json} & List files inside a scan resource \\
    \hline
      
\end{longtable}


The REST API is a sort of backbone of the automatization in XNAT workflow, it assures a orchestration of the container execution, and at the same time assuring  traceability and reproducibility. The REST API played a crucial role to develop a automatic workflow in the XNAT platform. The figure 3.1 illustrates the role of the REST API in the automatization


\begin{figure}[ht]
    \centering
    \def\svgwidth{0.9\linewidth}
    \input{RESTAPI.pdf_tex}
    \caption{Diagram: illustrates the role of the REST API in the automatization}
    \label{fig:workflow-steps}
\end{figure}

\section{The Automation Script}
The purpose of this chapter is to introduce the system in more detail. A Python script is used to combine all the steps into an automated workflow. The libraries used in this work include: \texttt{requests}\footnote{\url{https://www.w3schools.com/python/module_requests.asp} accessed on 10 August 2025}, \texttt{json}\footnote{\url{https://www.w3schools.com/python/python_json.asp} accessed on 10 August 2025}, \texttt{os}\footnote{\url{https://docs.python.org/3/library/os.html} accessed on 10 August 2025}, \texttt{subprocess}\footnote{\url{https://docs.python.org/3/library/subprocess.html} accessed on 10 August 2025}, \texttt{getpass}\footnote{\url{https://docs.python.org/3/library/getpass.html} accessed on 10 August 2025}, \texttt{sys}\footnote{\url{https://docs.python.org/3/library/sys.html} accessed on 10 August 2025}, and \texttt{urllib3}\footnote{\url{https://urllib3.readthedocs.io/en/stable/} accessed on 10 August 2025}.

The use of the Requests library was for creating the interaction with the web services of XNAT. The Python Requests library is the go-to solution for making HTTP requests in Python, thanks to its elegant and intuitive API that simplifies the process of interacting with web services and consuming data in the application.\footnote{\url{https://www.datacamp.com/tutorial/python-subprocess} accessed on 10 August 2025} The Sys module in Python provides access to variables and functions that interact closely with the Python interpreter and runtime environment.

Since a JSON command is written, the use of the JSON library was necessary. JSON is a syntax for storing and exchanging data. It is text, written with JavaScript Object Notation.\footnote{W3Schools, Python JSON}
The Python Subprocess module is a tool that allows running other programs or commands from your Python code. Using the Python Subprocess module resembles executing commands directly on the system computer using Python instead of typing them directly into the command prompt. This module makes it easy to automate Python code.\footnote{\url{https://www.datacamp.com/tutorial/python-subprocess} accessed on 10 August 2025}
Getpass() prompts the user for a password without echoing. The getpass module provides a secure way to handle password prompts where programs interact with the users via the terminal.\footnote{\url{https://www.geeksforgeeks.org/python/getpass-and-getuser-in-python-password-without-echo/} accessed on 10 August 2025}

The urllib3 library was used to disable the InsecureRequestWarning, which is normally shown when Requests connects to a site with an unverified SSL certificate. This approach helps keep the output clean and free of unnecessary warnings during the run of the script.

Currently, the system is running Docker Engine 28.3.0. The Docker Client version in use is 20.10.5+dfsg1, which communicates with the Docker Engine to issue commands and manage images and containers. The XNAT web application is running on version 1.9.1.1, as verified through the web interface.


\begin{figure}[ht]
  \centering
  \def\svgwidth{0.8\linewidth}
  \input{lib.pdf_tex}
  \caption{Schema: Core Libraries for Python Scripting in System Integration}
  \label{fig:diagram-core-libraries}
\end{figure}





\section{Architecture and organization of the Code}
The automation script is structured into 17 distinct parts, each one responsible for a specific step in the overall workflow.
During the development of the automation script, I closely followed the steps of the manual process, since I had already tested and completed it manually. This included writing a container script, writing a Dockerfile, building the image, writing a JSON command, and enabling the command first on the website and then on the project, with the last step being the launch of the container. I carefully repeated the same steps during the integration in XNAT. In other words, every structured part is composed of a function that is responsible for carrying out a step of the manual process.
 
  \section{The Dockerfile}
 
The first function responsible for writing the Dockerfile is called \texttt{def write\_dockerfile}, and it takes three arguments: the target directory for the Dockerfile, the name of the Python script to include, and an optional base Docker image (defaulting to \texttt{python:3.10-slim}, currently the fastest and slimmest image of Docker). The function creates the necessary folder (if it does not already exist), constructs the Dockerfile content, and writes it. The content of the Dockerfile is introduced with string interpolation and contains the base image and several commands such as \texttt{WORKDIR /app} (a working directory) and \texttt{COPY \{script\_filename\} /app/\{script\_filename\}} to copy the user script inside the image. The line \texttt{RUN pip install --no-cache-dir pandas} tells Docker to install the pandas Python library using pip during the build process of the Docker image, which helps reduce the overall image size and avoids unnecessary layers in the build process. The last command of the Dockerfile is \texttt{COPY requirements.txt /app/requirements.txt}, which provides the opportunity for the user to write in a separate text file all the libraries used in the container script, to be installed later during the image build process.


The \texttt{CMD} instruction was removed from the Dockerfile because it caused errors when running the container in XNAT. The issue was due to a conflict between the \texttt{CMD} instruction in the Dockerfile and the JSON command configuration, as both included the \texttt{python3} prefix. This led to a duplicate command execution, which caused the container to fail. By removing \texttt{CMD} from the Dockerfile, the execution logic is now fully controlled by XNAT through the JSON-based command, ensuring a successful launch of the Docker Container.


\lstdefinestyle{allblack}{
  basicstyle=\ttfamily\small\color{black},
  keywordstyle=\color{black},
  commentstyle=\color{black},
  stringstyle=\color{black},
  identifierstyle=\color{black},
  numberstyle=\color{black},
  rulecolor=\color{black},
  showstringspaces=false
}

\lstset{style=allblack}



\lstset{inputpath=en/content}

\lstinputlisting[
  inputencoding=cp1252, 
  language=Python,
  firstline=18,
  lastline=24,
  caption={Extracted from \texttt{automat\_f\_2.py} (lines 18--24)},
  label={lst:automat-snippet}
]{automat_f_2.py}

\noindent\footnotesize See the corresponding lines on GitHub:\url{ https://github.com/tanaebousfiha/XNAT-implemetation/blob/e3c1a547dc8241c4a24f651549069ee042c62393/Automation%20of%20the%20manuall%20Process%20of%20the%20xnat%20implementation/automat_f_2.py#L18-L24}

















The rest of the \texttt{def write\_dockerfile} ensures that the specified directory exists, then creates and writes a Dockerfile to that location. It constructs the full path to the file, writes the generated content into it, and prints a confirmation message.




\lstinputlisting[
  inputencoding=cp1252,  language=Python,
  firstline=25,
  lastline=29,
  caption={Extracted from \texttt{automat\_f\_2.py} (lines 25--29)},
  label={lst:automat-snippet}
]{automat_f_2.py}

\noindent\footnotesize See the corresponding lines on GitHub:\url{ https://github.com/tanaebousfiha/XNAT-implemetation/blob/e3c1a547dc8241c4a24f651549069ee042c62393/Automation%20of%20the%20manuall%20Process%20of%20the%20xnat%20implementation/automat_f_2.py#L25-L29}







This function ensures that the Dockerfile is written in an appropriate way and secures that all the dependencies are stored in the external requirements text file. It handles all possible cases and avoids the issues of errors and standard input errors.

\section{Building, Pushing and Tagging the Image}

When a command is deployed in XNAT and a container is launched, XNAT first checks whether the required Docker image is available on Docker Hub. This requires the user to have a Docker Hub account and to be logged in before running the script. For this reason, it is essential that the locally built image is correctly tagged and pushed to Docker Hub.

The function responsible for this process is \texttt{def build\_docker\_image}, which expects two parameters: the Dockerfile path (dockerfile\_path) and the name of the Docker image to be built (docker\_image\_name). Normally, we build an image in Docker with the command: \texttt{docker build .}


In the automation script, the full tag in the format \texttt{dockerhub\_username/docker\_image\_name} is provided. This ensures that the image is already linked to the correct Docker Hub name space and can be pushed directly after building.


\lstinputlisting[
  inputencoding=cp1252,  language=Python,
  firstline=38,
  lastline=46,
  caption={Extracted from \texttt{automat\_f\_2.py} (lines 38--46)},
  label={lst:automat-snippet}
]{automat_f_2.py}

\noindent\footnotesize See the corresponding lines on GitHub:\url{ https://github.com/tanaebousfiha/XNAT-implemetation/blob/e3c1a547dc8241c4a24f651549069ee042c62393/Automation%20of%20the%20manuall%20Process%20of%20the%20xnat%20implementation/automat_f_2.py#L38-L46}







Here, \texttt{subprocess.run} invokes the docker build command. The option \texttt{ -f dockerfile\_path} specifies which Dockerfile to use, while \texttt{-t full\_tag} sets the name and tag of the image. The final dot (.) indicates that the current directory will be used as the build context. The arguments \texttt{capture\_output=True} and text=True ensure that both stdout and stderr are captured and returned as strings, so that the script can handle them properly.

Once the image is built, it must be pushed to Docker Hub. This is done with the following block:
\lstinputlisting[
  inputencoding=cp1252,  language=Python,
  firstline=48,
  lastline=55,
  caption={Extracted from \texttt{automat\_f\_2.py} (lines 48--55)},
  label={lst:automat-snippet}
]{automat_f_2.py}

\noindent\footnotesize See the corresponding lines on GitHub:\url{ https://github.com/tanaebousfiha/XNAT-implemetation/blob/e3c1a547dc8241c4a24f651549069ee042c62393/Automation%20of%20the%20manuall%20Process%20of%20the%20xnat%20implementation/automat_f_2.py#L48-L55}





In a manual workflow, the push would be performed with the command:  \texttt{docker push image\_name}. This assumes that the user is already logged in. In the script, the same command is executed through  \texttt{subprocess.run}.

The key point is that the full image tag is constructed in the required Docker Hub format \texttt{(dockerhub\_username/docker\_image\_name)}. This guarantees that the built image is correctly associated with the user’s Docker Hub account, and that XNAT will be able to locate it when launching the container.

\section{The Prompt Function for the Required Input}

This function performs the task of capturing input from the user.
We have used this function in the script in multiple scenarios. The first was to take the Docker Hub username from the user. To customize the JSON command, we asked the user for the name of the command and its description. Overall, it is also used to take the username and password from the user’s login credentials. The function proceeds through all of these steps while running the script.

The function looks like this:
 
\lstinputlisting[
  inputencoding=cp1252,  language=Python,
  firstline=59,
  lastline=65,
  caption={Extracted from \texttt{automat\_f\_2.py} (lines 59--65)},
  label={lst:automat-snippet}
]{automat_f_2.py}

\noindent\footnotesize See the corresponding lines on GitHub:\url{ https://github.com/tanaebousfiha/XNAT-implemetation/blob/e3c1a547dc8241c4a24f651549069ee042c62393/Automation%20of%20the%20manuall%20Process%20of%20the%20xnat%20implementation/automat_f_2.py#L59-L65}


The \texttt{def get\_input} function uses a \texttt{while True} loop to keep asking until the user enters input. The \texttt{value.strip()} removes any whitespace from the user input. If the input is valid, the value is returned; if not, the message \texttt{Cannot be empty} will be printed.

\section{The Command Definition in JSON format}

To communicate the Docker image to XNAT, and consequently to run the container in the website, it is necessary to write a command definition in JSON format.\footnote{\url{ https://wiki.xnat.org/container-service/json-command-definition}}
Usually, the JSON-based command definition is personalized and customized depending on the main idea of the image. But in the automation case, the JSON-based command must be generalized for all cases, which means no matter which file is selected, the command will still handle it.

To achieve that, the function used is called \texttt{create\_json\_file}, which builds the configuration dictionary for a Docker-based XNAT command (for the XNAT Container Service), writes it to a \texttt{command.json} file, and returns the filename.

The function expects three parameters:

\texttt{docker\_image}: The Docker image to use (string).

\texttt{script\_filename}: The name of the Python script inside the container (string).

\texttt{mod\_data}: A dictionary holding user-provided metadata (names, descriptions, etc.).

Let us start analyzing the first block of the JSON command:



\lstinputlisting[
  inputencoding=cp1252,  language=Python,
  firstline=120,
  lastline=131,
  caption={Extracted from \texttt{automat\_f\_2.py} (lines 120--131)},
  label={lst:automat-snippet}
]{automat_f_2.py}

\noindent\footnotesize See the corresponding lines on GitHub:\url{ https://github.com/tanaebousfiha/XNAT-implemetation/blob/e3c1a547dc8241c4a24f651549069ee042c62393/Automation%20of%20the%20manuall%20Process%20of%20the%20xnat%20implementation/automat_f_2.py#L120-L131}



In this block, we are defining the name of the command, adding a description, and specifying the version and the type of the image.
The command line declares the actual command to run inside the container when invoked by XNAT. The placeholder \# is a template substitution (not a regex expression) that tells XNAT: \texttt{"When you launch the Docker command, replace \#input\_file\# with the actual file name/path that the user selected as input."} It does not define what a valid file looks like; instead, it marks a spot in the command where XNAT should "fill in" an actual value.


The mount configures the directory mappings (as Docker volumes) between XNAT and the Docker container. Most of the time, two are used: the input and the output.
We specified the path \texttt{/input} in the container and indicated whether the container can only read the files (\texttt{Not writable}) or can also write them (\texttt{Writable}).

The second part of command definition in JSON format:


\lstinputlisting[
  inputencoding=cp1252,  language=Python,
  firstline=132,
  lastline=160,
  caption={Extracted from \texttt{automat\_f\_2.py} (lines 132--150)},
  label={lst:automat-snippet}
]{automat_f_2.py}

\noindent\footnotesize See the corresponding lines on GitHub:\url{ https://github.com/tanaebousfiha/XNAT-implemetation/blob/e3c1a547dc8241c4a24f651549069ee042c62393/Automation%20of%20the%20manuall%20Process%20of%20the%20xnat%20implementation/automat_f_2.py#L132-L150}


This block defines the parameters that a user must provide as an input file when launching the container.
Let’s break down each field:

The \texttt{"name": "input\_files"} is used in other parts of the JSON as a reference---such as placeholders in the command line. In addition, we add an optional human-friendly description. The \texttt{"type"} indicates that the input accepts more than just text files, scans, or numbers; it specifies that each element in the input is specifically a file through the \texttt{"element"} field.

The \texttt{"required": true} flag means that if the input is not provided, the command cannot be run. The mount in this part links the input to a specific mount inside the container. All files provided by the user will appear in the \texttt{/input} directory inside the container. With \texttt{"multiple": true}, it is indicated that the user can upload or select more than one file for this input.

The same logic applies to the output part. The only additional point to note is the \texttt{"path": "."}, which means the output file will be placed at the top level of the \texttt{/output} directory. To allow more than one output file, the setting \texttt{"type": "files"} is used in the output block.

The final block in the command definition (JSON format):


\lstinputlisting[
  inputencoding=cp1252,  language=Python,
  firstline=152,
  lastline=173,
  caption={Extracted from \texttt{automat\_f\_2.py} (lines 152--173)},
  label={lst:automat-snippet}
]{automat_f_2.py}

\noindent\footnotesize See the corresponding lines on GitHub:\url{ https://github.com/tanaebousfiha/XNAT-implemetation/blob/c95b34d9d5a4b236f9b482e02258094384623892/Automation%20of%20the%20manuall%20Process%20of%20the%20xnat%20implementation/automat_f_2.py#L152-L173}




This block defines what will be displayed on the XNAT interface and connects the Docker command with XNAT's web interface and permission system. It controls how the command appears as a tool in XNAT, how it is integrated with projects or other data, and how inputs are handled.

The wrapper name is the technical name of the command inside XNAT. The \texttt{"label": mod\_data["label\_name"]} is a human-readable name shown in the XNAT \ac{UI}. The \texttt{"description": mod\_data["label\_description"]} is a description for the tool/wrapper, shown when users browse tools in XNAT. The \texttt{"context"} specifies where we want the container to appear in the XNAT interface. Since the main idea was to have one container on top of the structure of XNAT, here \texttt{["xnat:projectData"]} means this command is available at the project level.


In the \texttt{"external-input"} block, external entities from XNAT are defined. Because we used the project as the context for the command, we require in the external input that a project be selected. In more detail, the name and type must be "Project." This input must be provided, which is why \texttt{"required": true} is specified. We tell XNAT with \texttt{"load-children": true} to load (in the UI) the child objects of the project when showing this input.

In the \texttt{"output-handlers"} block, we control how the outputs from the command are stored and shown in XNAT after job completion. This output handler tells XNAT to take the result file produced by the command, store it as a resource under the project, and call that section ``Results'' in the UI. The \texttt{"as-a-child-of": "project"} specifies that the results are uploaded back into the XNAT project as new resources.

Finally, the script writes the command definition in JSON format, ensuring that the JSON command is saved in the correct format, ready to be uploaded to XNAT.

\section{Upload the Command in XNAT}

After writing the JSON-based command, the next step is to send it to XNAT. To achieve this, we have to use the appropriate REST API responsible for uploading the container command to XNAT.
We can find the list of all REST APIs under \texttt{Administer $\rightarrow$ Site Administration $\rightarrow$ Miscellaneous $\rightarrow$ Development Utilities $\rightarrow$ Swagger}.
To send the command to XNAT, we found that the responsible REST API is \texttt{POST}.\footnote{\url{https://xnat-dev.gwdg.de/xapi/swagger-ui.html\#/command-rest-api}}

The function responsible for this is \texttt{def send\_json\_to\_xnat}, and it expects four parameters: \texttt{json\_file\_path, xnat\_url, xnat\_user, xnat\_password}. When working with REST APIs, we first have to build the URL endpoint for XNAT’s command registration.
 
\lstinputlisting[
  inputencoding=cp1252,  language=Python,
  firstline=187,
  lastline=200,
  caption={Extracted from \texttt{automat\_f\_2.py} (lines 187--200)},
  label={lst:automat-snippet}
]{automat_f_2.py}

\noindent\footnotesize See the corresponding lines on GitHub:\url{ https://github.com/tanaebousfiha/XNAT-implemetation/blob/c95b34d9d5a4b236f9b482e02258094384623892/Automation%20of%20the%20manuall%20Process%20of%20the%20xnat%20implementation/automat_f_2.py#L187-L200}

This function takes the path that describes the JSON-based command, the base URL of the XNAT server, and the credentials for authentication. First, it constructs the correct REST API endpoint by appending \texttt{/xapi/commands} to the provided XNAT URL, ensuring that the command is sent to the appropriate API for command registration. It then opens the JSON file, loads its contents, and sends this data as a POST request to the API endpoint using \ac{HTTP} Basic Authentication with the supplied username and password. After making the request, the function examines the server’s response, and in each case provides feedback, helping the user quickly understand whether the command upload succeeded or if further action is needed to resolve an issue.

\section{Preparations to Launch the Container}

The goal of the previous steps is to launch the container in XNAT, but before that we need to perform some preparations. In line with the automation principle, we need to retrieve some information from the XNAT web service, and in this case we use the REST API technique as well. The first information that we need to extract after sending the JSON command to XNAT is the \texttt{Command ID} and the \texttt{Wrapper ID}.

 

\lstinputlisting[
  inputencoding=cp1252,  language=Python,
  firstline=204,
  lastline=228,
  caption={Extracted from \texttt{automat\_f\_2.py} (lines 204--228)},
  label={lst:automat-snippet}
]{automat_f_2.py}

\noindent\footnotesize See the corresponding lines on GitHub:\url{ https://github.com/tanaebousfiha/XNAT-implemetation/blob/a47cafecee7f9e467356ddb9f7939371e3d02e03/Automation%20of%20the%20manuall%20Process%20of%20the%20xnat%20implementation/automat_f_2.py#L204-L228}





The function takes as input the XNAT server’s hostname, user password, the name of the desired command, and the name of a specific wrapper. It first builds the correct XNAT REST API endpoint to list all the registered commands on XNAT.
Upon receiving a response, the function checks for a successful status (200 OK); otherwise, it reports the failure and exits. If only a command ID is needed (no wrapper specified), it returns the command’s ID directly. If a wrapper name is provided, the function searches for the wrapper within possible sections of the command definition under XNAT or the \texttt{"wrappers"} fields—returning the wrapper’s ID upon match. If the specified command or wrapper cannot be found, the function clearly reports this to the user.

After receiving the Command ID and the Wrapper ID, we proceed by enabling the command in the project and site-wide. For that, we use the two functions \texttt{def enable\_wrapper\_sitewide} and \texttt{def enable\_wrapper\_for\_project}, which both expect parameters such as the server’s hostname, user login and password, and the extracted Command ID and Wrapper ID. Each function builds the desired XNAT REST API endpoint (in this case, we used the \texttt{PUT} REST API), checks the status of the process, and provides feedback to the user to track the code’s progress.

\section{The Extraction of All Files from All Project Structures}

The function used in this part is \texttt{def get\_all\_files\_all\_levels}, and it collects all the files in the project data hierarchy (project, subjects, experiments/sessions, and scans) from an XNAT system using its REST API. We used the REST API endpoint \texttt{GET} for the extraction. The function proceeds by authenticating with the XNAT server using the provided user credentials and starts by gathering project-level files, querying all resource folders at the project root and listing every file found within them. At every step, the function structures each file into a dictionary containing hierarchical information (such as the level—project, subject, experiment, scan—and the relevant IDs), the file name, the resource folder it was found in, and an absolute URI for straightforward retrieval. By the end, it returns a comprehensive list of all file records across all levels in the project.\footnote{\url{ https://wiki.xnat.org/documentation/strategies-for-xnat-image-data-storage}last acced 25.08.2025}. Figure 3.2 explains the hierarchy where the files are stored.

\begin{figure}[ht]
    \centering
    \def\svgwidth{0.9\linewidth}
    \input{extraction.pdf_tex}
    \caption{Diagram: The Extraction of files from all the project structure}
    \label{fig:enter-label}
\end{figure}

\section{Launch the Container}

Arriving at the well-known part of launching the container, we use the function \texttt{def launch\_container\_with\_all\_files}. This function is designed to automatically launch a container with all the files previously extracted as input. It takes the XNAT server connection details, project and command identifiers, user authentication, the wrapper name, and a list of files to be processed.

The function first checks if any files are provided. A payload dictionary is then prepared, mapping the project ID and the input files string to the fields. Next, the function constructs the appropriate URL for launching the command. Before sending the launch request, the function prints diagnostic information, including the chosen files and payload. It then submits a \texttt{POST} request with the payload as JSON and user credentials for authentication. After sending the request, the function reports back to the user about the status and the response.


\lstinputlisting[
  inputencoding=cp1252,  language=Python,
  firstline=359,
  lastline=393,
  caption={Extracted from \texttt{automat\_f\_2.py} (lines 359--393)},
  label={lst:automat-snippet}
]{automat_f_2.py}

\noindent\footnotesize See the corresponding lines on GitHub:\url{ https://github.com/tanaebousfiha/XNAT-implemetation/blob/3a565f4b666a5f2938d5a41002049ee87cd33b61/Automation%20of%20the%20manuall%20Process%20of%20the%20xnat%20implementation/automat_f_2.py#L359-L393}




Figure 3.3 illustrates the steps to implement a container in XNAT.


\begin{figure}[ht]
    \centering
    \def\svgwidth{0.9\linewidth}
    \input{steps.pdf_tex}
    \caption{Diagram: Workflow Steps for the Implementation}
    \label{fig:workflow-steps}
\end{figure}


The figure 3.4 illustrates how the automation script facilitates the process of deploying a container in XNAT. It reduces all the steps.

\begin{figure}[ht]
    \centering
    \def\svgwidth{0.9\linewidth}
    \input{compare.pdf_tex}
    \caption{Diagram: Diagram illustrating the difference between the manual and the automatic process}
    \label{fig:enter-label}
\end{figure}



\section{Testing the Code}
After testing the code, we can see in the beginning \texttt{see the Appendix at the end}, the process actively requests input from the user in order to proceed with the integration. It started by asking the user for login credentials, then the Project ID that the user wants to process, and lastly, before proceeding with the creation and command sending to XNAT, it asked the user about the command name and the description.
After receiving all the information, the script commenced building the image, tagging, pushing, writing the JSON command, enabling the command, and lastly launching the container with all files.

\section{Results on XNAT}
The result that we came to after testing the code is that all the steps are working correctly, except that the container could not receive any files. With the \ac{STDout} view we found out that the container received zero files. 
 
\begin{lstlisting}[numbers=none]
View stdout (from file)
Inhalt von /input (rekursiv):
/input: []
Keine CSV-Datei in /input gefunden.
\end{lstlisting}


But interestingly, after searching in the container information, we noticed that the container in fact received the files and that the files are listed in the input part of the container input. 
Details of the test procedure are described in Appendix A \cite{bousfiha2025appendix}. Due to the fact that the list of files was extremely long, it was shortened. In summary, the container received a huge amount of files.

The results demonstrate two things. First, the automation script with the REST API worked correctly. Second, there is an issue with the container accessing the input files, despite them being listed as received.

\section{Discussion of the results}
This chapter presents an overview of the implementation solution, the technical challenges encountered during integration with XNAT, and the methods employed to overcome the issues. Several problems emerged throughout development, including data transmission failures, REST API inconsistencies, and JSON configuration mismatches.

The initial problem was that the container did not appear to receive any input files. To confirm this, a test was performed by adding a script within the container. The script was designed to write a file named \texttt{no\_file.txt} if no input file was detected at runtime. The successful upload of this file confirmed that while the container was running, it was not receiving actual input data.

Following the initial diagnosis, another test was conducted. Efforts were made to use the integration of the REST API within the container to retrieve files, process them, and upload the results. Despite the API being correctly called, no file results appeared in XNAT. 

Attention then shifted to the JSON command that defines the container command structure in XNAT. The JSON command was enhanced to include login credentials and more detailed output specifications. Multiple versions were tested, each with different contexts. Despite these efforts, no successful uploads occurred, and in some cases, the command itself was rejected by XNAT. 

It was hypothesized that the container execution timing could play a role in the failure. To test this, the automation script was modified to introduce a 10-second delay between each container execution. The assumption was that the host system might be under resource pressure when running multiple containers in rapid succession. However, introducing delays did not resolve the core issue: the container still did not receive input files.
%-------------------------------------------------------------------------------------------------------------------------



\section{Analysis of the Docker Approach: Current Limitations}

After analyzing the Docker Container method in both manual and automated scenarios, we identified several limitations, that requires further attention.
An advantage of using the Docker Container is the ability to automate the deployment workflow and launch either multiple containers or single workflows via scripting.
The Container approach was designed to be applicable on multiple structure of the XNAT. In other word depending on the intended case, users muss configure the container to process files within a specific structure of XNAT. However if the objective as to proceed all the files from all the existed structures in XNAT within a project, additional steps are needed, specifically extracting all the data from all the structures as well as extra work to relocate the processed files to their original directories after processing. Another important aspect is that, through the use of Docker containers, it is possible to selectively filter files based on their formats instance, if only CSV, SVG, TXT, or DICOM files are required. This targeted filtration can be configured within the JSON based format command, enabling precise data selection and processing according to specific project needs.

\section{The Workflow Data in XNAT}

In most cases, when we press the button \textit{Run Container} in XNAT manually, the data is automatically provided, and the container handles the data and reloads the results back into the system.  
In detail, when the container is launched, the platform orchestrates a series of data management and processing steps to facilitate the workflow. At first, the system generates a JSON specification. This specification includes information about the script and command line to be executed, the output file location, and the container input, ensuring that the containerized process has access to all relevant instructions.  
Furthermore, XNAT identifies the relevant data and prepares it for transfer to the designated computational environment. The data is then mounted or copied to a temporary directory within the host system, ensuring accessibility for the containerized analysis. Once the container is activated, it processes the input data according to the command-line script, generates the output data, and finally writes the output back to the designated result directory on the host.  

Assuming that the container has the ability to process a large number of files, there is also the possibility to increase the number of files that can be handled using the command \texttt{ulimit}.  
The fact that XNAT mounts or copies the data to a temporary directory within the host system reveals important insights into the underlying problem. Copying the data to the host system and mounting it into a volume means that the container has no direct access to the XNAT database, which can potentially lead to issues related to memory or disk space on the host. This approach may result in resource constraints.  
This issue can become particularly problematic when large datasets are involved. Although my specific test case involved a relatively small number of files, the container still failed to process the data successfully. This suggests that the problem may not be solely related to dataset size or resource limits.

The diagram below illustrates the workflow data for a clearer understanding.  

\begin{figure}[ht]
    \centering
    \def\svgwidth{\linewidth} 
    \input{xnat.pdf_tex}
    \caption{Diagram: XNAT Workflow for Container Integration}
    \label{fig:workflowxnat}
\end{figure}


To recapitulate, the Docker container method proved effective for launching containers within multiple project structures. However, it did not perform well when attempting to process all files across a single project structure. This limitation highlights a clear restriction and reduces the overall usefulness of the approach.

\section{Generalizability of the Docker Automation Method}

Currently the Docker Container is a sort of powerful method to insert AI in the XNAT. it performs well on single models and also bound to a specific data type such as CSV,DICOM. However, adapting the workflow to accommodate other data types still requires manual intervention and adjustment. This limitation affects the method’s reusability in varying contexts or projects.
Generalizability is particularly important in a way that the method should be accessible to users without programming expertise and adaptable for use in different institutions, datasets, and environments.
One way to enhance the generalizability is through the implementation of a graphical user Interface (GUI). The GUI method can make the Docker Container method more accessible and understandable to all users even without programming experiences. Consequently facilitating
the adoption of this method in different environments, institutions and datasets.  

\section{GUI Mockup for Docker Container Automation in XNAT}

For the purpose of creating more accessibility and to generalizability for non technical or experienced users. The Docker automation script developed in this project was visualized as a graphical user interface (GUI) mockup.
The following mockup in the Figure 3.7 does not represent a functional program , but it illustrates how the command line workflow can be illustrated. In other word it a representation of what the result on the Terminal looks like. Consequently it follows the same logical steps as the one on the terminal: (1) configuration of the container, (2)project selection, (3)file discovery,  (4)container launch, and (4) result visualization.


\begin{figure}[H]
    \centering
    \def\svgwidth{\linewidth} 
    \input{mockup.pdf_tex}
    \caption{Mockup example for the automation script}
    \label{fig:workflowxnat}
\end{figure}


\section{The Docker Container Approach and the Somnolink Project, sustainability aspects including FAIR criteria}

The Somnolink project is a nationwide initiative to improve the treatment and research of obstructive sleep apnea through better data sharing. The obstructive sleep apnea is the most prevalent disorder in clinical sleep laboratories, Therefore, the main goal of the Somnolink project is to improve the diagnosis and therapy of OSA.
The objectives of the project are aligned for improving the OSA care with the health data typically collected along the official patient pathway, as defined by the German guidelines. This pathway consists of four stages: (1) assessing pre-test probability through medical history and questionnaires, (2) conducting physical examinations in primary care, (3) performing outpatient sleep diagnostics, and (4) carrying out comprehensive sleep laboratory studies. Based on this structure, which data are relevant at each step is identified and proposed how data-driven methods such as machine learning–based decision support systems could assist clinicians in their decision-making. ~\cite{krefting_somnolink_2025}
In general, the implementation of Docker container technology is becoming increasingly prevalent within the Somnolink Project, due to It is notable that an OSA prediction model can be implemented with a Docker container within XNAT.
In this context, automating the Docker Container in XNAT offers a significant advantages. It allows the OSA prediction to be executed in a standardized manner. Such a automation is not only reducing the manual intervention, but also ensuring a consistent  workflow and facilitating  the integration of data-driven decision support into clinical practice. Which contribute to fulfilling the aim and the goals of this project.
\begin{figure}[ht]
    \centering
    \def\svgwidth{\linewidth} 
    \input{Somnolink.pdf_tex}
    \caption{Diagram: XNAT Workflow for Container Integration}
    \label{fig:workflowxnat}
\end{figure}

The figure 3.8 illustrates the structure of the OSA diagnostic pathway in relation to data collection, data driven support, and technical implementation.
The blue column shows the four steps of the German OSA patient pathway. The middle column summarizes the typical health data collected at each stage. And the last column underline the opportunity where machine learning or decision-support methods can be applied. 
The yellow banner highlights Docker container automation in XNAT  as the technical foundation that enable standardized and reproducible workflows across the steps.
Sustainability within Somnolink project covers both the technical stability and scientific traceability. Consequently the use of the Docker Containers contribute by offering reproducible computational environments, reducing maintenance demands, and facilitating collaboration across multiple sites. However, conformity to FAIR principles strengthens the long-term reusability of the developed solutions: The Container images are well stored in the Docker Hub (Findable), they are also accessible via standardized interfaces (Accessible), employ interoperable data formats (Interoperable), and are adaptable for use in new contexts (Reusable). This harmonized approach is essential for ensuring sustainable support of the Somnolink project’s objectives. 
\section{Sustainability of the Automation Script}

Another key strength for the developed automation script is its sustainability and long-term usability. The implementation is flexible and allows at the same time to the developers a reuse of the existing framework and modify only components that may need updating. Potential future changes. The Potential future changes can be :
- Updates to XNAT REST API endpoints.\\
- Authentication methods.\\
-  Alterations to the JSON-based format schema for command and wrapper definitions.\\
-  Docker base images in case a new better one is deprecated.\\
- XNAT project structures are extended with new contexts or data types.\\
However, the core workflow logic remains unaffected. Consequently this promote a efficient maintenance, supports sustainable software development practices.
























